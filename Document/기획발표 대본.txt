1. 딥러닝 기반 수어 번역 서비스, 수어랑 말해랑을 기획한 팀SLT 팀장 김군순입니다. 발표시작하겠습니다.

2. 다음과 같은 순서로 발표 진행하겠습니다.

3. 먼저, 제안배경입니다. 2022년 기준 청각장애인의 수는 42만명으로 전체 등록장애인 중 두 번째로 많은 수를 차지하고 있습니다. 청각장애인 중 수화언어를 사용하는 이들을 농인이라 칭하고, 농인이 사용하는 수화언어는 특정언어에 기반을 두는 것이 아닌 고유한 언어입니다. 그렇기 때문에 한국어, 한글을 익히지 않은 한국 농인들에게는 외국어나 다름없습니다.
실제로 약 40%의 농인은 자막서비스를 이용하지 않으며, 이용하는 농인들 중 완전히 자막을 이해하는 경우는 12.3%에 불과합니다.

4. 그렇기 때문에 흔히 농인-청인간 의사소통 또는 정보전달에 있어서 대안으로 생각하는 필담, 자막 등은 대안이 되기에는 어려움이 있습니다.
또한, 농인이 의사소통을 할 때 상대가 농인인 경우, 청인인 경우 모두 수어를 사용한 의사소통을 가장 선호한다고 합니다.

5. 수어를 활용한 의사소통, 정보전달을 위해서는 수어통역사들이 많이 필요합니다. 한국수어통역사협회에 따르면 등록된 수어통역사는 1973명으로 인력이 많이 부족한 상황입니다. 특히 지방은 인력이 현저히 떨어져 지방의 농인들을 통역서비스를 누리기 어렵습니다.

차별금지법으로 농인들 또한 청인들과 동등한 사회서비스를 제공받을 수 있도록 보장하려 하고있지만 현실적으로 보장받지 못하고 있습니다. 그렇기 때문에 수어통역사보다 부족하더라도 접근성이 쉬운 인공지능을 활용한 수어통역서비스가 필요하다고 생각합니다.

6. 개발목표는 우선적으로 다른 사회서비스를 누리는데 필수적인 교통서비스분야에 농인들의 접근성을 높이기 위한 서비스를 제공하는데 있습니다. 이 목표에 맞춰 주요 기능은 수어번역, 수어사전, 커뮤니티 3가지로 설정했습니다.

7. 수어번역 기능은 수어영상데이터를 학습한 모델을 활용합니다. 농인이 의사표현을 하고자 할 때, 카메라 앞에서 수어를 하면 그 동작을 인식하여 알맞게 번역한 후 청인에게 텍스트와 음성으로 출력하는 기능입니다.

8. 번역되는 동안 그리고 청인이 농인의 의사표현에 맞는 조치를 취하는 중 청인이 불안해하지 않도록 안내영상을 출력하도록 기획하고있습니다.
청인의 음성, 텍스트 또한 수어로 통역하는 서비스도 기획하고 있으나 시간관계상 불가능하다면 패턴화시킬 수 있는 답변들은 영상으로 미리 제작해 청인이 필요에 따라 농인에게 영상을 출력해줄 수 있도록 기획하고 있습니다.

9. 수어사전은 한국수어사전과 유사한 기능입니다. 평소에도 청인들이 수어에 대한 정보를 얻을 수 있도록 하는 기능입니다. 사전에 제작해놓지 못한 답변이 필요할 경우에도 이 기능을 사용할 수 있을것이라 판단합니다.

10. 커뮤니티 기능은 지속적으로 해당 서비스가 개선될 수 있도록 제공하는 기능입니다. 부족한 수어 데이터, 이용하는 시설별 필요한 답변 기능 등 건의를 받을 수 있고 사용자들끼리 해당 서비스에 대한 다양한 의견교환을 하는 기능입니다. 이 기능을 통해 지속적으로 데이터를 추가적으로 확보하고 서비스를 개선할 수 있습니다.

11. 수행방법입니다. 우선 데이터는 AI Hub에 있는 한국수어영상을 다운받고 한국수어사전에 등재된 수어영상을 크롤링하여 확보하였습니다.
그리고 다음과 같은 도구를 활용해 앞서 이야기한 기능들을 개발하려고 합니다.

12. 마지막으로 기대효과 및 활용방안입니다. 기대효과로는 크게 6가지가 있습니다. 다양한 분야에서 농인의 서비스 이용 편의성이 증가합니다. 또한 사회적 활동을 촉진할 수 있고, 여러 상황에서 청인의 농인에 대한 대응이 개선될 것입니다. 농인과 청인의 소통이 수월해지며 문화적 다양성, 상호 이해가 증진될 수 있고 장애인에 대한 인식이 증가하며 권리 또한 강화될 수 있을 것입니다.

13. 이상 발표는 마치고 Q&A시간 가지도록 하겠습니다.