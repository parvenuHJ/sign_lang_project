{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccba677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = open('log2.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2750b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Bidirectional, \n",
    "    LSTM, \n",
    "    GlobalAveragePooling1D, \n",
    "    Dense, \n",
    "    Input, \n",
    "    concatenate,\n",
    "    TimeDistributed,\n",
    "    Flatten\n",
    ")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac6857ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data'\n",
    "test_dir = 'data'\n",
    "# 비디오 파일 목록과 태그를 포함하는 리스트를 만드는 함수\n",
    "def create_data_list(data_dir):\n",
    "    data_list = []\n",
    "    # data_dir 안의 각 디렉토리에 대해 반복\n",
    "    for item in os.listdir(data_dir):\n",
    "        item_path = os.path.join(data_dir, item)  # 아이템의 전체 경로\n",
    "        # 해당 경로가 디렉토리인지 확인\n",
    "        if os.path.isdir(item_path):\n",
    "            # 디렉토리 내의 모든 파일을 나열\n",
    "            for file_name in os.listdir(item_path):\n",
    "                # 파일이 .mp4 파일인지 확인\n",
    "                if file_name.endswith('.mp4'):\n",
    "                    # 리스트에 태그와 파일 경로를 추가\n",
    "                    data_list.append((item, str('data'+'/'+item)+'/'+file_name))\n",
    "    return data_list\n",
    "\n",
    "# 함수를 사용해서 리스트를 생성\n",
    "train_list = create_data_list(train_dir)\n",
    "test_list = create_data_list(test_dir)\n",
    "# 리스트에서 데이터프레임을 생성\n",
    "train_df = pd.DataFrame(data=train_list, columns=['tag', 'video_name'])\n",
    "test_df = pd.DataFrame(data=test_list, columns=['tag', 'video_name'])\n",
    "# 필요한 경우 열 순서를 수정\n",
    "train_df = train_df.loc[:, ['tag', 'video_name']]\n",
    "test_df = test_df.loc[:, ['tag', 'video_name']]\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "train_file_path = 'train.csv'\n",
    "test_file_path = 'test.csv'\n",
    "train_df.to_csv(train_file_path, encoding='utf-8-sig', index=False)\n",
    "test_df.to_csv(test_file_path, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1756281",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(f\"Total video for training: {len(train_df)}\")\n",
    "print(f\"Total video for testing: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c4e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 장치 목록 가져오기\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    # GPU의 가상 메모리 제한을 6GB로 설정\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpu_devices[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 6)]\n",
    "    )\n",
    "    # set_memory_growth는 set_virtual_device_configuration과 함께 사용할 수 없습니다\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a9b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 500\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048\n",
    "SKELETON_FEATURES = 33*4\n",
    "HAND_FEATURES = 21*3*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0052228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨링\n",
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "labels = train_df[\"tag\"].values\n",
    "labels = label_processor(labels[..., None]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b79c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 이미지에서 중앙에 맞춰 정사각형으로 잘나내는 함수\n",
    "def crop_center_square(frame):\n",
    "    # 이미지의 높이(y)와 너비(x)를 가져옴\n",
    "    y, x = frame.shape[0:2]\n",
    "    # 이미지의 높이와 너비 중 더 작은 값을 선택하여 정사각형의 크기를 결정\n",
    "    min_dim = min(y, x)\n",
    "    # 정사각형을 이미지 중앙에 위치시키기 위해 시작점의 x좌표와 y좌표를 계산\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    # 계산된 시작점과 정사각형의 크기를 이용하여 이미지의 중앙 부분을 잘라냅니다.\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2a39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    a = np.array([a.x, a.y])  # 첫 번째 점\n",
    "    b = np.array([b.x, b.y])  # 중간 점 (팔꿈치)\n",
    "    c = np.array([c.x, c.y])  # 세 번째 점 (손목)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2f81fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일을 로드하고, 각 프레임을 처리하여 배열로 반환하는 함수\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, smooth_landmarks=True)\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "    # OpenCV를 사용하여 비디오 파일 열기\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    skeletons = []  # 스켈레톤 데이터\n",
    "    hand_landmarks = []  # 손 데이터\n",
    "    arm_angles = []  # 팔 각도 데이터\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # 비디오에서 프레임을 하나씩 읽기\n",
    "            ret, frame = cap.read()\n",
    "            # 읽을 프레임이 없으면 반복문을 종료\n",
    "            if not ret:\n",
    "                break\n",
    "            # 읽은 프레임에서 중앙의 정사각형 부분을 잘라냄\n",
    "            frame = crop_center_square(frame)\n",
    "            # 프레임의 크기를 지정된 크기로 조절\n",
    "            frame = cv2.resize(frame, resize)            \n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Mediapipe를 사용하여 스켈레톤 추출\n",
    "            hands_results = hands.process(frame_rgb)\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "           \n",
    "            if pose_results.pose_landmarks:\n",
    "                right_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "                right_elbow = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "                right_wrist = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "                left_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "                left_elbow = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "                left_wrist = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "\n",
    "                right_arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "                left_arm_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "\n",
    "                arm_angles.append((right_arm_angle, left_arm_angle))\n",
    "                skeletons.append(pose_results.pose_landmarks.landmark)\n",
    "                mp.solutions.drawing_utils.draw_landmarks(\n",
    "                    frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)            \n",
    "                \n",
    "            if hands_results.multi_hand_landmarks:\n",
    "                hand_landmarks_data = hands_results.multi_hand_landmarks\n",
    "                hand_landmarks.append(hand_landmarks_data)\n",
    "                for hand_lm in hand_landmarks_data:\n",
    "                    mp.solutions.drawing_utils.draw_landmarks(\n",
    "                        frame, hand_lm, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            cv2.imshow('Video Frame', frame)\n",
    "            cv2.waitKey(30)\n",
    "            # OpenCV는 BGR 색상 순서를 사용하므로, 이를 RGB 순서로 변경\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            # 처리된 프레임을 프레임 리스트에 추가\n",
    "            frames.append(frame)\n",
    "            # max_frames가 지정된 경우, 지정된 수의 프레임만큼만 처리\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        # 비디오 파일을 닫기\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        pose.close\n",
    "        hands.close\n",
    "    return np.array(frames), skeletons, hand_landmarks, np.array(arm_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "226bfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징추출\n",
    "def build_feature_extractor():\n",
    "    # 이미지 특징 추출을 위한 InceptionV3 모델\n",
    "    base_model = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    image_input = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed_image = preprocess_input(image_input)\n",
    "    image_features = base_model(preprocessed_image)\n",
    "\n",
    "    # Mediapipe 데이터 처리\n",
    "    mediapipe_input = keras.Input((258,))\n",
    "    mediapipe_features = keras.layers.Dense(258, activation=\"relu\")(mediapipe_input)\n",
    "    mediapipe_features = keras.layers.Dropout(0.5)(mediapipe_features)  # Dropout 추가\n",
    "\n",
    "    # 팔 각도 데이터 처리\n",
    "    arm_angle_input = keras.Input((2,))\n",
    "    arm_angle_features = keras.layers.Dense(16, activation=\"relu\")(arm_angle_input)\n",
    "    arm_angle_features = keras.layers.Dropout(0.5)(arm_angle_features)  # Dropout 추가\n",
    "\n",
    "    # 데이터 결합 및 추가 처리\n",
    "    combined_features = keras.layers.concatenate([image_features, mediapipe_features, arm_angle_features])\n",
    "    combined_features = keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(combined_features)  # 정규화 추가\n",
    "\n",
    "    # 최종 출력 레이어\n",
    "    outputs = keras.layers.Dense(5, activation=\"softmax\")(combined_features)  # 클래스 수에 맞게 조정\n",
    "\n",
    "    return keras.Model(inputs=[image_input, mediapipe_input, arm_angle_input], outputs=outputs, name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a307a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손 랜드마크를 2개로 제한한 코드\n",
    "def preprocess_skeleton_data(skeleton):\n",
    "    # 스켈레톤 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not skeleton:\n",
    "        return np.zeros(SKELETON_FEATURES)\n",
    "    # 스켈레톤 데이터를 1차원 배열로 변환\n",
    "    skeleton_array = np.array([[lm.x, lm.y, lm.z] for lm in skeleton]).flatten()    \n",
    "    # 부족한 부분을 0으로 채우기\n",
    "    skeleton_array = np.pad(skeleton_array, ((0, max(0, SKELETON_FEATURES - len(skeleton_array)))))    \n",
    "    return skeleton_array\n",
    "\n",
    "def preprocess_hand_data(hand_landmarks):\n",
    "    # 손 랜드마크 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not hand_landmarks or len(hand_landmarks) < 2:\n",
    "        return np.zeros(HAND_FEATURES)\n",
    "    \n",
    "    # 첫 번째와 두 번째 손에 대한 랜드마크만 처리\n",
    "    hand_data = []\n",
    "    for hand_lm in hand_landmarks[:2]:  # 첫 번째와 두 번째 손만 처리\n",
    "        lm_array = np.array([[lm.x, lm.y, lm.z] for lm in hand_lm.landmark]).flatten()\n",
    "        hand_data.extend(lm_array)\n",
    "\n",
    "    # 부족한 부분을 0으로 채우기\n",
    "    hand_data = np.pad(hand_data, ((0, max(0, HAND_FEATURES - len(hand_data)))))\n",
    "\n",
    "    return np.array(hand_data)\n",
    "\n",
    "def preprocess_arm_angle_data(arm_angles):\n",
    "    # 팔 각도 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not arm_angles:\n",
    "        return np.zeros(2)  # 오른팔, 왼팔 각각의 각도\n",
    "    return np.array(arm_angles)\n",
    "\n",
    "def preprocess_image(frame):    \n",
    "    frame = image.img_to_array(frame[0])  # frame[0]으로 변경\n",
    "    frame = preprocess_input(frame)  # ResNet50의 전처리 함수를 사용하여 정규화\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae3a9d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_all_video(df):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "\n",
    "    # Mediapipe 데이터를 저장할 배열 초기화\n",
    "    frame_skeletons = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, SKELETON_FEATURES), dtype=\"float16\")\n",
    "    frame_hands = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, HAND_FEATURES), dtype=\"float16\")\n",
    "    \n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float16\")\n",
    "    \n",
    "    # 이미지 데이터 저장할 배열 초기화\n",
    "    frame_images = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=\"float16\")\n",
    "    # 팔 각도 데이터 저장할 배열 초기화\n",
    "    frame_arm_angles = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, 2), dtype=\"float16\")  # 2는 팔 각도 데이터 차원\n",
    "    \n",
    "    # 특징 추출기 모델 초기화\n",
    "    feature_extractor = build_feature_extractor()\n",
    "\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        frames, skeletons, hands, arm_angles = load_video(path)\n",
    "        video_length = min(MAX_SEQ_LENGTH, len(frames))\n",
    "\n",
    "        for i in range(video_length):\n",
    "            # 이미지 데이터 전처리 및 특징 추출\n",
    "            image_feature = preprocess_image(frames[i:i+1])\n",
    "            image_feature = np.expand_dims(image_feature, axis=0)  # 차원 확장\n",
    "                      \n",
    "            # Mediapipe 데이터 전처리\n",
    "            skeleton_feature = preprocess_skeleton_data(skeletons[i])\n",
    "            hand_feature = preprocess_hand_data(hands[i])\n",
    "            combined_mediapipe_data = np.concatenate([skeleton_feature, hand_feature])\n",
    "            combined_mediapipe_data = np.expand_dims(combined_mediapipe_data, axis=0)\n",
    "            \n",
    "            # 팔 각도 데이터 전처리\n",
    "            arm_angle_feature = np.array(arm_angles[i])\n",
    "            arm_angle_feature = np.expand_dims(arm_angle_feature, axis=0)\n",
    "            \n",
    "            # 모델 예측\n",
    "            try:\n",
    "                # feature_extractor에 모든 데이터 전달\n",
    "                frame_feature = feature_extractor.predict([image_feature, combined_mediapipe_data, arm_angle_feature], verbose=0)\n",
    "                frame_features[idx, i, :] = frame_feature  # 데이터 저장\n",
    "            except Exception as e:\n",
    "                print(\"Error during prediction:\", e)\n",
    "            \n",
    "            # 데이터 저장\n",
    "            frame_images[idx, i, :] = frames[i]  # 원본 이미지 데이터 저장\n",
    "            frame_skeletons[idx, i, :] = skeleton_feature\n",
    "            frame_hands[idx, i, :] = hand_feature\n",
    "            frame_arm_angles[idx, i, :] = arm_angle_feature\n",
    "            frame_masks[idx, i] = 1\n",
    "            \n",
    "    # 반환 값에 Mediapipe 데이터 포함\n",
    "    return (frame_features, frame_skeletons, frame_hands, frame_masks, frame_arm_angles), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d332bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # INFO 메시지를 숨긴다.\n",
    "tf.get_logger().setLevel('ERROR')         # TensorFlow 로그를 ERROR 레벨로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8221829b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = prepare_all_video(train_df)\n",
    "test_data, test_labels = train_data, train_labels\n",
    "train_labels = np.squeeze(train_labels)\n",
    "test_labels = np.squeeze(test_labels)\n",
    "sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8b7dfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 20, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "617610e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    \n",
    "    # 기존 이미지 특징에 대한 입력\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    skeleton_input = keras.Input((MAX_SEQ_LENGTH, SKELETON_FEATURES))\n",
    "    hand_input = keras.Input((MAX_SEQ_LENGTH, HAND_FEATURES))\n",
    "    arm_angle_input = keras.Input((MAX_SEQ_LENGTH, 2))  # 팔 각도 데이터 입력 레이어\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    \n",
    "    # LSTM 레이어 처리\n",
    "    x = LSTM(64, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Mediapipe 데이터 처리\n",
    "    y_skeleton = GlobalAveragePooling1D()(skeleton_input)\n",
    "    y_hand = GlobalAveragePooling1D()(hand_input)\n",
    "\n",
    "    # 팔 각도 데이터 처리\n",
    "    y_arm_angle = GlobalAveragePooling1D()(arm_angle_input)\n",
    "\n",
    "    # 데이터 결합\n",
    "    combined = concatenate([x, y_skeleton, y_hand, y_arm_angle])\n",
    "\n",
    "    # 추가 처리\n",
    "    z = Dense(16, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(combined)\n",
    "    output = Dense(len(class_vocab), activation=\"softmax\", kernel_regularizer=regularizers.l2(0.01))(z)\n",
    "    \n",
    "    # 모델 생성 및 컴파일\n",
    "    lstm_model = keras.Model([frame_features_input, skeleton_input, hand_input, arm_angle_input, mask_input], output)\n",
    "    lstm_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c13067e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 23.5514 - accuracy: 0.2500\n",
      "Epoch 1: val_loss improved from inf to 8.91311, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 10s 10s/step - loss: 23.5514 - accuracy: 0.2500 - val_loss: 8.9131 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.4327 - accuracy: 0.2500\n",
      "Epoch 2: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 22.4327 - accuracy: 0.2500 - val_loss: 9.1320 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.3495 - accuracy: 0.2500\n",
      "Epoch 3: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 21.3495 - accuracy: 0.2500 - val_loss: 9.3280 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.2692 - accuracy: 0.2500\n",
      "Epoch 4: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 20.2692 - accuracy: 0.2500 - val_loss: 9.4980 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.1916 - accuracy: 0.2500\n",
      "Epoch 5: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.1916 - accuracy: 0.2500 - val_loss: 9.6444 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.1165 - accuracy: 0.2500\n",
      "Epoch 6: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 18.1165 - accuracy: 0.2500 - val_loss: 9.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.0439 - accuracy: 0.2500\n",
      "Epoch 7: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 17.0439 - accuracy: 0.2500 - val_loss: 9.8844 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.9735 - accuracy: 0.2500\n",
      "Epoch 8: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 15.9735 - accuracy: 0.2500 - val_loss: 9.9854 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.9050 - accuracy: 0.2500\n",
      "Epoch 9: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 14.9050 - accuracy: 0.2500 - val_loss: 10.0770 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8382 - accuracy: 0.2500\n",
      "Epoch 10: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 13.8382 - accuracy: 0.2500 - val_loss: 10.1610 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.7727 - accuracy: 0.2500\n",
      "Epoch 11: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 12.7727 - accuracy: 0.2500 - val_loss: 10.2385 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.7082 - accuracy: 0.2500\n",
      "Epoch 12: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 11.7082 - accuracy: 0.2500 - val_loss: 10.3122 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.6456 - accuracy: 0.2500\n",
      "Epoch 13: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10.6456 - accuracy: 0.2500 - val_loss: 10.3924 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5948 - accuracy: 0.2500\n",
      "Epoch 14: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 9.5948 - accuracy: 0.2500 - val_loss: 10.5389 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6198 - accuracy: 0.2500\n",
      "Epoch 15: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 8.6198 - accuracy: 0.2500 - val_loss: 10.9391 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9997 - accuracy: 0.2500\n",
      "Epoch 16: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 7.9997 - accuracy: 0.2500 - val_loss: 11.6159 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9559 - accuracy: 0.2500\n",
      "Epoch 17: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 7.9559 - accuracy: 0.2500 - val_loss: 12.2560 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.1385 - accuracy: 0.2500\n",
      "Epoch 18: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.1385 - accuracy: 0.2500 - val_loss: 12.6364 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.2572 - accuracy: 0.2500\n",
      "Epoch 19: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.2572 - accuracy: 0.2500 - val_loss: 12.7403 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.2510 - accuracy: 0.2500\n",
      "Epoch 20: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.2510 - accuracy: 0.2500 - val_loss: 12.6078 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.1289 - accuracy: 0.2500\n",
      "Epoch 21: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.1289 - accuracy: 0.2500 - val_loss: 12.2816 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9111 - accuracy: 0.2500\n",
      "Epoch 22: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 7.9111 - accuracy: 0.2500 - val_loss: 11.7992 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.6176 - accuracy: 0.2500\n",
      "Epoch 23: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 7.6176 - accuracy: 0.2500 - val_loss: 11.1933 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.2671 - accuracy: 0.2500\n",
      "Epoch 24: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 7.2671 - accuracy: 0.2500 - val_loss: 10.4955 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8791 - accuracy: 0.2500\n",
      "Epoch 25: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 6.8791 - accuracy: 0.2500 - val_loss: 9.7406 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.4769 - accuracy: 0.2500\n",
      "Epoch 26: val_loss did not improve from 8.91311\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 6.4769 - accuracy: 0.2500 - val_loss: 8.9709 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.0898 - accuracy: 0.2500\n",
      "Epoch 27: val_loss improved from 8.91311 to 8.24015, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 6.0898 - accuracy: 0.2500 - val_loss: 8.2402 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7528 - accuracy: 0.2500\n",
      "Epoch 28: val_loss improved from 8.24015 to 7.60860, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.7528 - accuracy: 0.2500 - val_loss: 7.6086 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.4962 - accuracy: 0.2692\n",
      "Epoch 29: val_loss improved from 7.60860 to 7.11534, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.4962 - accuracy: 0.2692 - val_loss: 7.1153 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 5.3286 - accuracy: 0.2308\n",
      "Epoch 30: val_loss improved from 7.11534 to 6.75095, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.3286 - accuracy: 0.2308 - val_loss: 6.7510 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2302 - accuracy: 0.2500\n",
      "Epoch 31: val_loss improved from 6.75095 to 6.48171, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.2302 - accuracy: 0.2500 - val_loss: 6.4817 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1669 - accuracy: 0.2500\n",
      "Epoch 32: val_loss improved from 6.48171 to 6.27715, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.1669 - accuracy: 0.2500 - val_loss: 6.2771 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1089 - accuracy: 0.2500\n",
      "Epoch 33: val_loss improved from 6.27715 to 6.11716, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.1089 - accuracy: 0.2500 - val_loss: 6.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0386 - accuracy: 0.2500\n",
      "Epoch 34: val_loss improved from 6.11716 to 5.99019, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.0386 - accuracy: 0.2500 - val_loss: 5.9902 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.9498 - accuracy: 0.2500\n",
      "Epoch 35: val_loss improved from 5.99019 to 5.88977, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.9498 - accuracy: 0.2500 - val_loss: 5.8898 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8433 - accuracy: 0.2500\n",
      "Epoch 36: val_loss improved from 5.88977 to 5.81163, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.8433 - accuracy: 0.2500 - val_loss: 5.8116 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7243 - accuracy: 0.2500\n",
      "Epoch 37: val_loss improved from 5.81163 to 5.75133, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.7243 - accuracy: 0.2500 - val_loss: 5.7513 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5988 - accuracy: 0.2500\n",
      "Epoch 38: val_loss improved from 5.75133 to 5.70270, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.5988 - accuracy: 0.2500 - val_loss: 5.7027 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4712 - accuracy: 0.2500\n",
      "Epoch 39: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.4712 - accuracy: 0.2500 - val_loss: 5.7367 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3613 - accuracy: 0.2692\n",
      "Epoch 40: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.3613 - accuracy: 0.2692 - val_loss: 5.9632 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2954 - accuracy: 0.2500\n",
      "Epoch 41: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.2954 - accuracy: 0.2500 - val_loss: 6.2088 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2455 - accuracy: 0.2308\n",
      "Epoch 42: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.2455 - accuracy: 0.2308 - val_loss: 6.4373 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1952 - accuracy: 0.2692\n",
      "Epoch 43: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.1952 - accuracy: 0.2692 - val_loss: 6.6334 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1352 - accuracy: 0.2500\n",
      "Epoch 44: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.1352 - accuracy: 0.2500 - val_loss: 6.7905 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0618 - accuracy: 0.2500\n",
      "Epoch 45: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.0618 - accuracy: 0.2500 - val_loss: 6.9094 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.9765 - accuracy: 0.2500\n",
      "Epoch 46: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.9765 - accuracy: 0.2500 - val_loss: 6.9959 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8841 - accuracy: 0.2692\n",
      "Epoch 47: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.8841 - accuracy: 0.2692 - val_loss: 7.0582 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7907 - accuracy: 0.2500\n",
      "Epoch 48: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.7907 - accuracy: 0.2500 - val_loss: 7.1046 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7018 - accuracy: 0.2308\n",
      "Epoch 49: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.7018 - accuracy: 0.2308 - val_loss: 7.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6209 - accuracy: 0.2885\n",
      "Epoch 50: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.6209 - accuracy: 0.2885 - val_loss: 7.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5495 - accuracy: 0.3077\n",
      "Epoch 51: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.5495 - accuracy: 0.3077 - val_loss: 7.2083 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4871 - accuracy: 0.2692\n",
      "Epoch 52: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.4871 - accuracy: 0.2692 - val_loss: 7.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4319 - accuracy: 0.2308\n",
      "Epoch 53: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.4319 - accuracy: 0.2308 - val_loss: 7.2785 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3814 - accuracy: 0.2500\n",
      "Epoch 54: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3814 - accuracy: 0.2500 - val_loss: 7.3169 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3329 - accuracy: 0.2115\n",
      "Epoch 55: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.3329 - accuracy: 0.2115 - val_loss: 7.3573 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2841 - accuracy: 0.2115\n",
      "Epoch 56: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2841 - accuracy: 0.2115 - val_loss: 7.3993 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2332 - accuracy: 0.2115\n",
      "Epoch 57: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2332 - accuracy: 0.2115 - val_loss: 7.4425 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 3.1792 - accuracy: 0.2115\n",
      "Epoch 58: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.1792 - accuracy: 0.2115 - val_loss: 7.4865 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1217 - accuracy: 0.2115\n",
      "Epoch 59: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.1217 - accuracy: 0.2115 - val_loss: 7.5307 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0610 - accuracy: 0.2115\n",
      "Epoch 60: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.0610 - accuracy: 0.2115 - val_loss: 7.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9980 - accuracy: 0.2115\n",
      "Epoch 61: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.9980 - accuracy: 0.2115 - val_loss: 7.6177 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9336 - accuracy: 0.2115\n",
      "Epoch 62: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.9336 - accuracy: 0.2115 - val_loss: 7.6589 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8688 - accuracy: 0.2500\n",
      "Epoch 63: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.8688 - accuracy: 0.2500 - val_loss: 7.6973 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8044 - accuracy: 0.2308\n",
      "Epoch 64: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8044 - accuracy: 0.2308 - val_loss: 7.7317 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7411 - accuracy: 0.2500\n",
      "Epoch 65: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.7411 - accuracy: 0.2500 - val_loss: 7.7612 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6791 - accuracy: 0.2692\n",
      "Epoch 66: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6791 - accuracy: 0.2692 - val_loss: 7.7848 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6186 - accuracy: 0.2692\n",
      "Epoch 67: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6186 - accuracy: 0.2692 - val_loss: 7.8020 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5594 - accuracy: 0.2692\n",
      "Epoch 68: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5594 - accuracy: 0.2692 - val_loss: 7.8126 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5013 - accuracy: 0.2500\n",
      "Epoch 69: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5013 - accuracy: 0.2500 - val_loss: 7.8169 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4442 - accuracy: 0.2500\n",
      "Epoch 70: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4442 - accuracy: 0.2500 - val_loss: 7.8155 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3877 - accuracy: 0.2500\n",
      "Epoch 71: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3877 - accuracy: 0.2500 - val_loss: 7.8095 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3317 - accuracy: 0.2115\n",
      "Epoch 72: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3317 - accuracy: 0.2115 - val_loss: 7.8003 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2761 - accuracy: 0.2308\n",
      "Epoch 73: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2761 - accuracy: 0.2308 - val_loss: 7.7895 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2209 - accuracy: 0.2115\n",
      "Epoch 74: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2209 - accuracy: 0.2115 - val_loss: 7.7788 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1661 - accuracy: 0.2115\n",
      "Epoch 75: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1661 - accuracy: 0.2115 - val_loss: 7.7698 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1118 - accuracy: 0.2500\n",
      "Epoch 76: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1118 - accuracy: 0.2500 - val_loss: 7.7640 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0581 - accuracy: 0.2500\n",
      "Epoch 77: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0581 - accuracy: 0.2500 - val_loss: 7.7633 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0054 - accuracy: 0.2500\n",
      "Epoch 78: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0054 - accuracy: 0.2500 - val_loss: 7.7687 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9543 - accuracy: 0.2500\n",
      "Epoch 79: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9543 - accuracy: 0.2500 - val_loss: 7.7805 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9025 - accuracy: 0.2500\n",
      "Epoch 80: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9025 - accuracy: 0.2500 - val_loss: 7.7992 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8527 - accuracy: 0.2500\n",
      "Epoch 81: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8527 - accuracy: 0.2500 - val_loss: 7.8262 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8078 - accuracy: 0.2115\n",
      "Epoch 82: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8078 - accuracy: 0.2115 - val_loss: 7.8597 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7682 - accuracy: 0.2115\n",
      "Epoch 83: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7682 - accuracy: 0.2115 - val_loss: 7.8999 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7338 - accuracy: 0.2308\n",
      "Epoch 84: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7338 - accuracy: 0.2308 - val_loss: 7.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7051 - accuracy: 0.2692\n",
      "Epoch 85: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7051 - accuracy: 0.2692 - val_loss: 7.9945 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6820 - accuracy: 0.2885\n",
      "Epoch 86: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6820 - accuracy: 0.2885 - val_loss: 8.0436 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6640 - accuracy: 0.2500\n",
      "Epoch 87: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6640 - accuracy: 0.2500 - val_loss: 8.0908 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6500 - accuracy: 0.2500\n",
      "Epoch 88: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6500 - accuracy: 0.2500 - val_loss: 8.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6398 - accuracy: 0.2500\n",
      "Epoch 89: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6398 - accuracy: 0.2500 - val_loss: 8.1742 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6327 - accuracy: 0.2692\n",
      "Epoch 90: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6327 - accuracy: 0.2692 - val_loss: 8.2088 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6277 - accuracy: 0.2692\n",
      "Epoch 91: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6277 - accuracy: 0.2692 - val_loss: 8.2384 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6242 - accuracy: 0.2885\n",
      "Epoch 92: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6242 - accuracy: 0.2885 - val_loss: 8.2631 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6213 - accuracy: 0.2692\n",
      "Epoch 93: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6213 - accuracy: 0.2692 - val_loss: 8.2832 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6186 - accuracy: 0.2885\n",
      "Epoch 94: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6186 - accuracy: 0.2885 - val_loss: 8.2992 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6155 - accuracy: 0.2308\n",
      "Epoch 95: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6155 - accuracy: 0.2308 - val_loss: 8.3117 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6120 - accuracy: 0.2885\n",
      "Epoch 96: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6120 - accuracy: 0.2885 - val_loss: 8.3213 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6081 - accuracy: 0.2308\n",
      "Epoch 97: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6081 - accuracy: 0.2308 - val_loss: 8.3284 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6039 - accuracy: 0.2692\n",
      "Epoch 98: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6039 - accuracy: 0.2692 - val_loss: 8.3338 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5999 - accuracy: 0.2692\n",
      "Epoch 99: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5999 - accuracy: 0.2692 - val_loss: 8.3376 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5964 - accuracy: 0.2500\n",
      "Epoch 100: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5964 - accuracy: 0.2500 - val_loss: 8.3400 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5936 - accuracy: 0.2308\n",
      "Epoch 101: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5936 - accuracy: 0.2308 - val_loss: 8.3412 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5918 - accuracy: 0.2500\n",
      "Epoch 102: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5918 - accuracy: 0.2500 - val_loss: 8.3410 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5907 - accuracy: 0.2308\n",
      "Epoch 103: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5907 - accuracy: 0.2308 - val_loss: 8.3394 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5902 - accuracy: 0.2308\n",
      "Epoch 104: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5902 - accuracy: 0.2308 - val_loss: 8.3362 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5901 - accuracy: 0.2308\n",
      "Epoch 105: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5901 - accuracy: 0.2308 - val_loss: 8.3320 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5900 - accuracy: 0.2308\n",
      "Epoch 106: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5900 - accuracy: 0.2308 - val_loss: 8.3272 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5898 - accuracy: 0.2500\n",
      "Epoch 107: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5898 - accuracy: 0.2500 - val_loss: 8.3228 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5894 - accuracy: 0.2692\n",
      "Epoch 108: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5894 - accuracy: 0.2692 - val_loss: 8.3198 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5890 - accuracy: 0.2308\n",
      "Epoch 109: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5890 - accuracy: 0.2308 - val_loss: 8.3194 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5884 - accuracy: 0.2308\n",
      "Epoch 110: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5884 - accuracy: 0.2308 - val_loss: 8.3226 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5878 - accuracy: 0.2115\n",
      "Epoch 111: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5878 - accuracy: 0.2115 - val_loss: 8.3302 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5871 - accuracy: 0.2308\n",
      "Epoch 112: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5871 - accuracy: 0.2308 - val_loss: 8.3426 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5862 - accuracy: 0.2115\n",
      "Epoch 113: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5862 - accuracy: 0.2115 - val_loss: 8.3600 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5850 - accuracy: 0.2308\n",
      "Epoch 114: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5850 - accuracy: 0.2308 - val_loss: 8.3823 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5835 - accuracy: 0.2308\n",
      "Epoch 115: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5835 - accuracy: 0.2308 - val_loss: 8.4092 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5818 - accuracy: 0.2308\n",
      "Epoch 116: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5818 - accuracy: 0.2308 - val_loss: 8.4398 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5799 - accuracy: 0.2308\n",
      "Epoch 117: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5799 - accuracy: 0.2308 - val_loss: 8.4735 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5779 - accuracy: 0.2308\n",
      "Epoch 118: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5779 - accuracy: 0.2308 - val_loss: 8.5093 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5760 - accuracy: 0.2308\n",
      "Epoch 119: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5760 - accuracy: 0.2308 - val_loss: 8.5460 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5743 - accuracy: 0.2308\n",
      "Epoch 120: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5743 - accuracy: 0.2308 - val_loss: 8.5827 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5728 - accuracy: 0.2500\n",
      "Epoch 121: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5728 - accuracy: 0.2500 - val_loss: 8.6183 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5715 - accuracy: 0.2500\n",
      "Epoch 122: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5715 - accuracy: 0.2500 - val_loss: 8.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5705 - accuracy: 0.2308\n",
      "Epoch 123: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5705 - accuracy: 0.2308 - val_loss: 8.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5695 - accuracy: 0.2308\n",
      "Epoch 124: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5695 - accuracy: 0.2308 - val_loss: 8.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5687 - accuracy: 0.2308\n",
      "Epoch 125: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5687 - accuracy: 0.2308 - val_loss: 8.7356 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5680 - accuracy: 0.2308\n",
      "Epoch 126: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5680 - accuracy: 0.2308 - val_loss: 8.7571 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5673 - accuracy: 0.2500\n",
      "Epoch 127: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5673 - accuracy: 0.2500 - val_loss: 8.7757 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5667 - accuracy: 0.2308\n",
      "Epoch 128: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5667 - accuracy: 0.2308 - val_loss: 8.7917 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5661 - accuracy: 0.2115\n",
      "Epoch 129: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5661 - accuracy: 0.2115 - val_loss: 8.8056 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5655 - accuracy: 0.2115\n",
      "Epoch 130: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5655 - accuracy: 0.2115 - val_loss: 8.8180 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5650 - accuracy: 0.2115\n",
      "Epoch 131: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5650 - accuracy: 0.2115 - val_loss: 8.8291 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5645 - accuracy: 0.1923\n",
      "Epoch 132: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5645 - accuracy: 0.1923 - val_loss: 8.8394 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5640 - accuracy: 0.2115\n",
      "Epoch 133: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5640 - accuracy: 0.2115 - val_loss: 8.8493 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5635 - accuracy: 0.2115\n",
      "Epoch 134: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5635 - accuracy: 0.2115 - val_loss: 8.8589 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5629 - accuracy: 0.2692\n",
      "Epoch 135: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5629 - accuracy: 0.2692 - val_loss: 8.8749 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5624 - accuracy: 0.1923\n",
      "Epoch 136: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5624 - accuracy: 0.1923 - val_loss: 8.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5617 - accuracy: 0.2115\n",
      "Epoch 137: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5617 - accuracy: 0.2115 - val_loss: 8.8920 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5611 - accuracy: 0.2692\n",
      "Epoch 138: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5611 - accuracy: 0.2692 - val_loss: 8.9035 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5606 - accuracy: 0.2692\n",
      "Epoch 139: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5606 - accuracy: 0.2692 - val_loss: 8.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5599 - accuracy: 0.2692\n",
      "Epoch 140: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5599 - accuracy: 0.2692 - val_loss: 8.9291 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5596 - accuracy: 0.2308\n",
      "Epoch 141: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5596 - accuracy: 0.2308 - val_loss: 8.9388 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5589 - accuracy: 0.2500\n",
      "Epoch 142: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5589 - accuracy: 0.2500 - val_loss: 8.9480 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5584 - accuracy: 0.3077\n",
      "Epoch 143: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5584 - accuracy: 0.3077 - val_loss: 8.9578 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5580 - accuracy: 0.3077\n",
      "Epoch 144: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5580 - accuracy: 0.3077 - val_loss: 8.9678 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5573 - accuracy: 0.2500\n",
      "Epoch 145: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5573 - accuracy: 0.2500 - val_loss: 8.9774 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5569 - accuracy: 0.2500\n",
      "Epoch 146: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5569 - accuracy: 0.2500 - val_loss: 8.9858 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5563 - accuracy: 0.2500\n",
      "Epoch 147: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5563 - accuracy: 0.2500 - val_loss: 8.9939 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5557 - accuracy: 0.2692\n",
      "Epoch 148: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5557 - accuracy: 0.2692 - val_loss: 9.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5553 - accuracy: 0.2692\n",
      "Epoch 149: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5553 - accuracy: 0.2692 - val_loss: 9.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5547 - accuracy: 0.2692\n",
      "Epoch 150: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5547 - accuracy: 0.2692 - val_loss: 9.0206 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5542 - accuracy: 0.2308\n",
      "Epoch 151: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5542 - accuracy: 0.2308 - val_loss: 9.0301 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5538 - accuracy: 0.2308\n",
      "Epoch 152: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5538 - accuracy: 0.2308 - val_loss: 9.0398 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5533 - accuracy: 0.2308\n",
      "Epoch 153: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5533 - accuracy: 0.2308 - val_loss: 9.0498 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5528 - accuracy: 0.2308\n",
      "Epoch 154: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5528 - accuracy: 0.2308 - val_loss: 9.0600 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5524 - accuracy: 0.2308\n",
      "Epoch 155: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5524 - accuracy: 0.2308 - val_loss: 9.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5519 - accuracy: 0.2115\n",
      "Epoch 156: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5519 - accuracy: 0.2115 - val_loss: 9.0796 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5515 - accuracy: 0.2115\n",
      "Epoch 157: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5515 - accuracy: 0.2115 - val_loss: 9.0890 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5511 - accuracy: 0.2115\n",
      "Epoch 158: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5511 - accuracy: 0.2115 - val_loss: 9.0982 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5506 - accuracy: 0.2115\n",
      "Epoch 159: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5506 - accuracy: 0.2115 - val_loss: 9.1069 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5502 - accuracy: 0.2115\n",
      "Epoch 160: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5502 - accuracy: 0.2115 - val_loss: 9.1149 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5498 - accuracy: 0.2115\n",
      "Epoch 161: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5498 - accuracy: 0.2115 - val_loss: 9.1221 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5494 - accuracy: 0.2115\n",
      "Epoch 162: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5494 - accuracy: 0.2115 - val_loss: 9.1287 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5490 - accuracy: 0.2115\n",
      "Epoch 163: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5490 - accuracy: 0.2115 - val_loss: 9.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5486 - accuracy: 0.2115\n",
      "Epoch 164: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5486 - accuracy: 0.2115 - val_loss: 9.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5482 - accuracy: 0.2115\n",
      "Epoch 165: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5482 - accuracy: 0.2115 - val_loss: 9.1468 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5478 - accuracy: 0.2115\n",
      "Epoch 166: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5478 - accuracy: 0.2115 - val_loss: 9.1525 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5474 - accuracy: 0.2308\n",
      "Epoch 167: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5474 - accuracy: 0.2308 - val_loss: 9.1579 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5470 - accuracy: 0.2115\n",
      "Epoch 168: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5470 - accuracy: 0.2115 - val_loss: 9.1633 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5467 - accuracy: 0.2115\n",
      "Epoch 169: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5467 - accuracy: 0.2115 - val_loss: 9.1690 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5463 - accuracy: 0.2115\n",
      "Epoch 170: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5463 - accuracy: 0.2115 - val_loss: 9.1748 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5459 - accuracy: 0.2115\n",
      "Epoch 171: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5459 - accuracy: 0.2115 - val_loss: 9.1808 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5455 - accuracy: 0.2308\n",
      "Epoch 172: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5455 - accuracy: 0.2308 - val_loss: 9.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5452 - accuracy: 0.2308\n",
      "Epoch 173: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5452 - accuracy: 0.2308 - val_loss: 9.1928 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5448 - accuracy: 0.2308\n",
      "Epoch 174: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5448 - accuracy: 0.2308 - val_loss: 9.1987 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5445 - accuracy: 0.2115\n",
      "Epoch 175: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5445 - accuracy: 0.2115 - val_loss: 9.2046 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5441 - accuracy: 0.2115\n",
      "Epoch 176: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5441 - accuracy: 0.2115 - val_loss: 9.2105 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5437 - accuracy: 0.2115\n",
      "Epoch 177: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5437 - accuracy: 0.2115 - val_loss: 9.2162 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5434 - accuracy: 0.2308\n",
      "Epoch 178: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5434 - accuracy: 0.2308 - val_loss: 9.2218 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5431 - accuracy: 0.2308\n",
      "Epoch 179: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5431 - accuracy: 0.2308 - val_loss: 9.2271 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5427 - accuracy: 0.2308\n",
      "Epoch 180: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5427 - accuracy: 0.2308 - val_loss: 9.2323 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5424 - accuracy: 0.2308\n",
      "Epoch 181: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5424 - accuracy: 0.2308 - val_loss: 9.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5420 - accuracy: 0.2308\n",
      "Epoch 182: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5420 - accuracy: 0.2308 - val_loss: 9.2426 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5417 - accuracy: 0.2308\n",
      "Epoch 183: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5417 - accuracy: 0.2308 - val_loss: 9.2477 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5413 - accuracy: 0.2115\n",
      "Epoch 184: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5413 - accuracy: 0.2115 - val_loss: 9.2528 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5410 - accuracy: 0.2115\n",
      "Epoch 185: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5410 - accuracy: 0.2115 - val_loss: 9.2577 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5407 - accuracy: 0.2308\n",
      "Epoch 186: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5407 - accuracy: 0.2308 - val_loss: 9.2627 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5403 - accuracy: 0.2308\n",
      "Epoch 187: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5403 - accuracy: 0.2308 - val_loss: 9.2677 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5400 - accuracy: 0.2308\n",
      "Epoch 188: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5400 - accuracy: 0.2308 - val_loss: 9.2728 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5397 - accuracy: 0.2115\n",
      "Epoch 189: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5397 - accuracy: 0.2115 - val_loss: 9.2778 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5394 - accuracy: 0.2115\n",
      "Epoch 190: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5394 - accuracy: 0.2115 - val_loss: 9.2827 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5390 - accuracy: 0.2115\n",
      "Epoch 191: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5390 - accuracy: 0.2115 - val_loss: 9.2874 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5387 - accuracy: 0.2115\n",
      "Epoch 192: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5387 - accuracy: 0.2115 - val_loss: 9.2920 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5384 - accuracy: 0.2308\n",
      "Epoch 193: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5384 - accuracy: 0.2308 - val_loss: 9.2966 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5381 - accuracy: 0.2115\n",
      "Epoch 194: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5381 - accuracy: 0.2115 - val_loss: 9.3011 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5378 - accuracy: 0.2115\n",
      "Epoch 195: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5378 - accuracy: 0.2115 - val_loss: 9.3054 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5374 - accuracy: 0.2115\n",
      "Epoch 196: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5374 - accuracy: 0.2115 - val_loss: 9.3095 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5371 - accuracy: 0.2115\n",
      "Epoch 197: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5371 - accuracy: 0.2115 - val_loss: 9.3135 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5368 - accuracy: 0.2115\n",
      "Epoch 198: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5368 - accuracy: 0.2115 - val_loss: 9.3175 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5365 - accuracy: 0.2115\n",
      "Epoch 199: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5365 - accuracy: 0.2115 - val_loss: 9.3214 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5362 - accuracy: 0.2115\n",
      "Epoch 200: val_loss did not improve from 5.70270\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5362 - accuracy: 0.2115 - val_loss: 9.3253 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4.7175 - accuracy: 0.2000\n",
      "Test accuracy: 20.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE= 128\n",
    "def run_experiment():\n",
    "    filepath = \"tmp/video_classifier_lstm.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1], train_data[2],train_data[4], train_data[3]],\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    \n",
    "    _, accuracy = seq_model.evaluate(\n",
    "        [test_data[0], test_data[1], test_data[2], test_data[4], test_data[3]],\n",
    "        test_labels\n",
    "    )\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    # 손실 및 정확도 그래프 출력\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    # 손실 그래프\n",
    "    ax1 = plt.subplot(1, 1, 1)\n",
    "    ax1.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', color='blue', linestyle='dashed')\n",
    "    ax1.set_title('Training and Validation Loss and Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax1.legend(loc='upper left')\n",
    "    # 정확도 그래프를 같은 그래프에 추가\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(history.history['accuracy'], label='Train Accuracy', color='green')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green', linestyle='dashed')\n",
    "    ax2.set_ylabel('Accuracy', color='green')\n",
    "    ax2.tick_params(axis='y', labelcolor='green')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    seq_model.save('test_lstm_model2.h5')\n",
    "    \n",
    "    return history, seq_model\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "671a5950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: data/NIA_SL_SEN0203/NIA_SL_SEN0203_REAL12_F.mp4\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "NIA_SL_SEN0159 : 66.22%\n",
      "NIA_SL_SEN0011 : 24.30%\n",
      "NIA_SL_SEN0013 :  9.15%\n",
      "NIA_SL_SEN0275 :  0.33%\n",
      "NIA_SL_SEN0203 :  0.00%\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames, skeletons, hands, arm_angles):\n",
    "    num_frames = frames.shape[1]\n",
    "    video_length = min(MAX_SEQ_LENGTH, num_frames)\n",
    "\n",
    "    frame_mask = np.zeros((1, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros((1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float16\")\n",
    "    frame_skeletons = np.zeros((1, MAX_SEQ_LENGTH, SKELETON_FEATURES), dtype=\"float16\")\n",
    "    frame_hands = np.zeros((1, MAX_SEQ_LENGTH, HAND_FEATURES), dtype=\"float16\")\n",
    "    frame_images = np.zeros((1, MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=\"float16\")\n",
    "    frame_arm_angles = np.zeros((1, MAX_SEQ_LENGTH, 2), dtype=\"float16\")  # 2는 팔 각도 데이터 차원\n",
    "    \n",
    "    feature_extractor = Sequential([\n",
    "        ResNet50(include_top=False, weights='imagenet', pooling='avg'),  # 예시로 평균 풀링 사용\n",
    "        Dense(NUM_FEATURES, activation='relu')  # NUM_FEATURES에 맞는 덴스 레이어 추가\n",
    "    ])\n",
    "    \n",
    "    for j in range(video_length):\n",
    "        # 이미지 데이터 전처리 및 특징 추출\n",
    "        image_feature = preprocess_image(frames[j:j+1])\n",
    "        image_feature = np.expand_dims(image_feature, axis=0)\n",
    "        feature_result = feature_extractor.predict(image_feature)\n",
    "\n",
    "        # frame_images 대신 feature_result를 사용\n",
    "        frame_features[0, j] = feature_result\n",
    "\n",
    "        # Mediapipe 데이터 전처리\n",
    "        skeleton_feature = preprocess_skeleton_data(skeletons[j])\n",
    "        hand_feature = preprocess_hand_data(hands[j])        \n",
    "        arm_angle_feature = np.array(arm_angles[j])\n",
    "\n",
    "        frame_skeletons[0, j] = skeleton_feature\n",
    "        frame_hands[0, j] = hand_feature\n",
    "        frame_mask[0, j] = 1        \n",
    "        frame_arm_angles[0, j] = arm_angle_feature\n",
    "\n",
    "    return frame_features, frame_skeletons, frame_hands, frame_mask, frame_images, frame_arm_angles\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    frames, skeletons, hands, arm_angles = load_video(path)    \n",
    "    try:\n",
    "        num_frames = frames.shape[1]\n",
    "    except IndexError:\n",
    "        print(\"Error: Unable to determine the number of frames. Frames shape:\", frames.shape)\n",
    "        return None\n",
    "    \n",
    "    frame_features, frame_skeletons, frame_hands, frame_mask, frame_images, frame_arm_angles = prepare_single_video(frames, skeletons, hands, arm_angles)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_skeletons, frame_hands,frame_arm_angles, frame_mask])[0]\n",
    "    \n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"{class_vocab[i]} : {probabilities[i] * 100:5.2f}%\")\n",
    "    \n",
    "    return frame_images\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
