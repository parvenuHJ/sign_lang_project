{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d2750b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6857ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'E:/군순/train'\n",
    "test_dir = 'E:/군순/train'\n",
    "# 비디오 파일 목록과 태그를 포함하는 리스트를 만드는 함수\n",
    "def create_data_list(data_dir):\n",
    "    data_list = []\n",
    "    # data_dir 안의 각 디렉토리에 대해 반복\n",
    "    for item in os.listdir(data_dir):\n",
    "        item_path = os.path.join(data_dir, item)  # 아이템의 전체 경로\n",
    "        # 해당 경로가 디렉토리인지 확인\n",
    "        if os.path.isdir(item_path):\n",
    "            # 디렉토리 내의 모든 파일을 나열\n",
    "            for file_name in os.listdir(item_path):\n",
    "                # 파일이 .mp4 파일인지 확인\n",
    "                if file_name.endswith('.mp4'):\n",
    "                    # 리스트에 태그와 파일 경로를 추가\n",
    "                    data_list.append((item, str('E:/군순/train'+'/'+item)+'/'+file_name))\n",
    "    return data_list\n",
    "\n",
    "# 함수를 사용해서 리스트를 생성\n",
    "train_list = create_data_list(train_dir)\n",
    "test_list = create_data_list(test_dir)\n",
    "# 리스트에서 데이터프레임을 생성\n",
    "train_df = pd.DataFrame(data=train_list, columns=['tag', 'video_name'])\n",
    "test_df = pd.DataFrame(data=test_list, columns=['tag', 'video_name'])\n",
    "# 필요한 경우 열 순서를 수정\n",
    "train_df = train_df.loc[:, ['tag', 'video_name']]\n",
    "test_df = test_df.loc[:, ['tag', 'video_name']]\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "train_file_path = 'train.csv'\n",
    "test_file_path = 'test.csv'\n",
    "train_df.to_csv(train_file_path, encoding='utf-8-sig', index=False)\n",
    "test_df.to_csv(test_file_path, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1756281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total video for training: 75\n",
      "Total video for testing: 75\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(f\"Total video for training: {len(train_df)}\")\n",
    "print(f\"Total video for testing: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a9b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048\n",
    "SKELETON_FEATURES = 33*4\n",
    "HAND_FEATURES = 21*3*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0052228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 라벨링\n",
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "labels = train_df[\"tag\"].values\n",
    "labels = label_processor(labels[..., None]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b79c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 이미지에서 중앙에 맞춰 정사각형으로 잘나내는 함수\n",
    "def crop_center_square(frame):\n",
    "    # 이미지의 높이(y)와 너비(x)를 가져옴\n",
    "    y, x = frame.shape[0:2]\n",
    "    # 이미지의 높이와 너비 중 더 작은 값을 선택하여 정사각형의 크기를 결정\n",
    "    min_dim = min(y, x)\n",
    "    # 정사각형을 이미지 중앙에 위치시키기 위해 시작점의 x좌표와 y좌표를 계산\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    # 계산된 시작점과 정사각형의 크기를 이용하여 이미지의 중앙 부분을 잘라냅니다.\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f81fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일을 로드하고, 각 프레임을 처리하여 배열로 반환하는 함수\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, smooth_landmarks=True)\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "    # OpenCV를 사용하여 비디오 파일 열기\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    skeletons = []  # 스켈레톤 데이터\n",
    "    hand_landmarks = []  # 손 데이터\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # 비디오에서 프레임을 하나씩 읽기\n",
    "            ret, frame = cap.read()\n",
    "            # 읽을 프레임이 없으면 반복문을 종료\n",
    "            if not ret:\n",
    "                break\n",
    "            # 읽은 프레임에서 중앙의 정사각형 부분을 잘라냄\n",
    "            frame = crop_center_square(frame)\n",
    "            # 프레임의 크기를 지정된 크기로 조절\n",
    "            frame = cv2.resize(frame, resize)            \n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Mediapipe를 사용하여 스켈레톤 추출\n",
    "            hands_results = hands.process(frame_rgb)\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "           \n",
    "            if pose_results.pose_landmarks:\n",
    "                skeletons.append(pose_results.pose_landmarks.landmark)\n",
    "            if hands_results.multi_hand_landmarks:\n",
    "                hand_landmarks.append(hands_results.multi_hand_landmarks)\n",
    "            \n",
    "            # OpenCV는 BGR 색상 순서를 사용하므로, 이를 RGB 순서로 변경\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            # 처리된 프레임을 프레임 리스트에 추가\n",
    "            frames.append(frame)\n",
    "            # max_frames가 지정된 경우, 지정된 수의 프레임만큼만 처리\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        # 비디오 파일을 닫기\n",
    "        cap.release()\n",
    "        pose.close\n",
    "        hands.close\n",
    "    return np.array(frames), skeletons, hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226bfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징추출\n",
    "def build_feature_extractor():\n",
    "    # 이미지 특징 추출을 위한 InceptionV3 모델\n",
    "    base_model = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    image_input = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed_image = preprocess_input(image_input)\n",
    "    image_features = base_model(preprocessed_image)\n",
    "\n",
    "    # Mediapipe 데이터를 위한 입력 레이어 및 처리 레이어\n",
    "    # 예시로, Mediapipe 데이터의 차원을 상정하여 입력 레이어를 정의\n",
    "    mediapipe_input = keras.Input((258,))\n",
    "    mediapipe_features = keras.layers.Dense(258, activation=\"relu\")(mediapipe_input)\n",
    "\n",
    "    # 이미지 특징과 Mediapipe 데이터의 결합\n",
    "    combined_features = keras.layers.concatenate([image_features, mediapipe_features])\n",
    "\n",
    "    # 최종 모델\n",
    "    outputs = keras.layers.Dense(15, activation=\"softmax\")(combined_features)\n",
    "    return keras.Model(inputs=[image_input, mediapipe_input], outputs=outputs, name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a307a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손 랜드마크를 2개로 제한한 코드\n",
    "def preprocess_skeleton_data(skeleton):\n",
    "    # 스켈레톤 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not skeleton:\n",
    "        return np.zeros(SKELETON_FEATURES)\n",
    "    # 스켈레톤 데이터를 1차원 배열로 변환\n",
    "    skeleton_array = np.array([[lm.x, lm.y, lm.z] for lm in skeleton]).flatten()    \n",
    "    # 부족한 부분을 0으로 채우기\n",
    "    skeleton_array = np.pad(skeleton_array, ((0, max(0, SKELETON_FEATURES - len(skeleton_array)))) )    \n",
    "    return skeleton_array\n",
    "\n",
    "def preprocess_hand_data(hand_landmarks):\n",
    "    # 손 랜드마크 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not hand_landmarks or len(hand_landmarks) < 2:\n",
    "        return np.zeros(HAND_FEATURES)\n",
    "    \n",
    "    # 첫 번째와 두 번째 손에 대한 랜드마크만 처리\n",
    "    hand_data = []\n",
    "    for i in range(2):\n",
    "        hand_lm = hand_landmarks[i]\n",
    "        lm_array = np.array([[lm.x, lm.y, lm.z] for lm in hand_lm.landmark]).flatten()\n",
    "        hand_data.extend(lm_array)\n",
    "\n",
    "    # 부족한 부분을 0으로 채우기\n",
    "    hand_data = np.pad(hand_data, ((0, max(0, HAND_FEATURES - len(hand_data)))))\n",
    "\n",
    "    return np.array(hand_data)\n",
    "\n",
    "def preprocess_image(frame):    \n",
    "    frame = image.img_to_array(frame[0])  # frame[0]으로 변경\n",
    "    frame = preprocess_input(frame)  # ResNet50의 전처리 함수를 사용하여 정규화\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae3a9d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_all_video(df):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "\n",
    "    # Mediapipe 데이터를 저장할 배열 초기화\n",
    "    frame_skeletons = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, SKELETON_FEATURES), dtype=\"float32\")\n",
    "    frame_hands = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, HAND_FEATURES), dtype=\"float32\")\n",
    "    \n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "    \n",
    "    # 이미지 데이터 저장할 배열 초기화\n",
    "    frame_images = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=\"float32\")\n",
    "    \n",
    "    # 특징 추출기 모델 초기화\n",
    "    feature_extractor = build_feature_extractor()\n",
    "\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        frames, skeletons, hands = load_video(path)\n",
    "        video_length = min(MAX_SEQ_LENGTH, frames.shape[1])\n",
    "\n",
    "        for i in range(video_length):\n",
    "            # 이미지 데이터 전처리 및 특징 추출\n",
    "            image_feature = preprocess_image(frames[i:i+1])\n",
    "            image_feature = np.expand_dims(image_feature, axis=0)  # 차원 확장\n",
    "            \n",
    "            # InceptionV3 모델에 전처리된 이미지 전달\n",
    "            image_feature = feature_extractor.layers[0](image_feature)            \n",
    "            \n",
    "            # Mediapipe 데이터 전처리\n",
    "            skeleton_feature = preprocess_skeleton_data(skeletons[i])\n",
    "            hand_feature = preprocess_hand_data(hands[i])\n",
    "            combined_mediapipe_data = np.concatenate([skeleton_feature, hand_feature])\n",
    "            \n",
    "            # 차원 확장\n",
    "            combined_mediapipe_data = np.expand_dims(combined_mediapipe_data, axis=0)\n",
    "            \n",
    "            # 크기 확인\n",
    "            print(\"Image Feature shape:\", image_feature.shape)\n",
    "            print(\"Combined Mediapipe Data shape:\", combined_mediapipe_data.shape)\n",
    "            \n",
    "            # 데이터 저장\n",
    "            frame_images[idx, i, :] = image_feature           \n",
    "\n",
    "            # Mediapipe 데이터의 전처리 및 저장\n",
    "            frame_skeletons[idx, i, :] = skeleton_feature\n",
    "            frame_hands[idx, i, :] = hand_feature\n",
    "\n",
    "            frame_masks[idx, i] = 1\n",
    "            \n",
    "            # 모델 예측\n",
    "            try:\n",
    "                frame_feature = feature_extractor.predict([image_feature, combined_mediapipe_data])\n",
    "                print(\"Prediction shape:\", frame_feature.shape)\n",
    "            except Exception as e:\n",
    "                print(\"Error during prediction:\", e)\n",
    "\n",
    "    # 반환 값에 Mediapipe 데이터 포함\n",
    "    return (frame_features, frame_skeletons, frame_hands, frame_masks), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = prepare_all_video(train_df)\n",
    "test_data, test_labels = train_data, train_labels\n",
    "train_labels = np.squeeze(train_labels)\n",
    "test_labels = np.squeeze(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "617610e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    \n",
    "    # 기존 이미지 특징에 대한 입력\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    # Mediapipe 데이터에 대한 추가 입력 레이어\n",
    "    skeleton_input = keras.Input((MAX_SEQ_LENGTH, SKELETON_FEATURES))\n",
    "    hand_input = keras.Input((MAX_SEQ_LENGTH, HAND_FEATURES))    \n",
    "    \n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    \n",
    "    # 이미지 특징 처리를 위한 GRU 레이어\n",
    "    x = keras.layers.GRU(64, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = keras.layers.GRU(32, return_sequences=True)(x)\n",
    "    x = keras.layers.GlobalAveragePooling1D()(x)  # 형태 변경\n",
    "    \n",
    "    # Mediapipe 데이터를 처리하는 추가 네트워크 레이어 (예시)\n",
    "    # 여기서는 간단히 Dense 레이어를 사용했지만, 필요에 따라 다른 구조를 사용할 수 있습니다.\n",
    "    y_skeleton = keras.layers.GlobalAveragePooling1D()(skeleton_input)\n",
    "    y_hand = keras.layers.GlobalAveragePooling1D()(hand_input)    \n",
    "\n",
    "    # 모든 특징을 결합\n",
    "    combined = keras.layers.concatenate([x, y_skeleton, y_hand])\n",
    "\n",
    "    # 결합된 특징에 대한 추가 처리\n",
    "    z = keras.layers.Dense(16, activation=\"relu\")(combined)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(z)\n",
    "    \n",
    "    rnn_model = keras.Model([frame_features_input, skeleton_input, hand_input, mask_input], output)\n",
    "    rnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c13067e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.8564 - accuracy: 0.0667  \n",
      "Epoch 1: val_loss improved from inf to 2.95400, saving model to ./tmp\\video_classifier.h5\n",
      "8/8 [==============================] - 12s 458ms/step - loss: 2.8564 - accuracy: 0.0667 - val_loss: 2.9540 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.7343 - accuracy: 0.0714  \n",
      "Epoch 2: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.7276 - accuracy: 0.0833 - val_loss: 3.1088 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 2.6829 - accuracy: 0.1042\n",
      "Epoch 3: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.6703 - accuracy: 0.0833 - val_loss: 3.1955 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.6587 - accuracy: 0.1071\n",
      "Epoch 4: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.6549 - accuracy: 0.1000 - val_loss: 3.2434 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.6551 - accuracy: 0.0893  \n",
      "Epoch 5: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.6523 - accuracy: 0.0833 - val_loss: 3.3155 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.6323 - accuracy: 0.0893\n",
      "Epoch 6: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.6397 - accuracy: 0.0833 - val_loss: 3.3749 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.6411 - accuracy: 0.0714  \n",
      "Epoch 7: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.6347 - accuracy: 0.0667 - val_loss: 3.4050 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.6062 - accuracy: 0.0714\n",
      "Epoch 8: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.6225 - accuracy: 0.0667 - val_loss: 3.4683 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.6142 - accuracy: 0.0714\n",
      "Epoch 9: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.6127 - accuracy: 0.0667 - val_loss: 3.5153 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.6084 - accuracy: 0.0714\n",
      "Epoch 10: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.6040 - accuracy: 0.0833 - val_loss: 3.5788 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.6070 - accuracy: 0.0714  \n",
      "Epoch 11: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.6017 - accuracy: 0.0833 - val_loss: 3.6512 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5936 - accuracy: 0.0893  \n",
      "Epoch 12: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5968 - accuracy: 0.0833 - val_loss: 3.7447 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5888 - accuracy: 0.0893  \n",
      "Epoch 13: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5871 - accuracy: 0.0833 - val_loss: 3.8391 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5794 - accuracy: 0.0714\n",
      "Epoch 14: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5740 - accuracy: 0.0833 - val_loss: 3.9478 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5777 - accuracy: 0.0536  \n",
      "Epoch 15: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.5699 - accuracy: 0.0667 - val_loss: 4.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5584 - accuracy: 0.0714  \n",
      "Epoch 16: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5641 - accuracy: 0.0667 - val_loss: 4.1687 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5519 - accuracy: 0.0893\n",
      "Epoch 17: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5576 - accuracy: 0.0833 - val_loss: 4.2512 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5586 - accuracy: 0.0536\n",
      "Epoch 18: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5517 - accuracy: 0.0833 - val_loss: 4.3313 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5462 - accuracy: 0.0893\n",
      "Epoch 19: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5442 - accuracy: 0.0833 - val_loss: 4.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5374 - accuracy: 0.0893\n",
      "Epoch 20: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5429 - accuracy: 0.0833 - val_loss: 4.5237 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5298 - accuracy: 0.0893\n",
      "Epoch 21: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.5336 - accuracy: 0.0833 - val_loss: 4.6144 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5378 - accuracy: 0.0714  \n",
      "Epoch 22: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5310 - accuracy: 0.0833 - val_loss: 4.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5313 - accuracy: 0.1071  \n",
      "Epoch 23: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5420 - accuracy: 0.1000 - val_loss: 4.8077 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5226 - accuracy: 0.0536  \n",
      "Epoch 24: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.5219 - accuracy: 0.0500 - val_loss: 4.8833 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5229 - accuracy: 0.0893  \n",
      "Epoch 25: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5242 - accuracy: 0.0833 - val_loss: 4.9682 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5201 - accuracy: 0.0714\n",
      "Epoch 26: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5209 - accuracy: 0.0667 - val_loss: 5.0494 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5103 - accuracy: 0.0714  \n",
      "Epoch 27: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.5118 - accuracy: 0.0833 - val_loss: 5.1278 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5056 - accuracy: 0.0714  \n",
      "Epoch 28: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.5091 - accuracy: 0.0667 - val_loss: 5.2226 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5074 - accuracy: 0.0893  \n",
      "Epoch 29: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5089 - accuracy: 0.0833 - val_loss: 5.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.5002 - accuracy: 0.0893\n",
      "Epoch 30: val_loss did not improve from 2.95400\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.5074 - accuracy: 0.0833 - val_loss: 5.4033 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step - loss: 2.7688 - accuracy: 0.0667\n",
      "Test accuracy: 6.67%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE=8\n",
    "def run_experiment():\n",
    "    filepath = \"./tmp/video_classifier.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1], train_data[2], train_data[3]],  # 수정된 입력 데이터\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    \n",
    "    _, accuracy = seq_model.evaluate(\n",
    "        [test_data[0], test_data[1], test_data[2], test_data[3]],  # 수정된 입력 데이터\n",
    "        test_labels\n",
    "    )\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    # 손실 및 정확도 그래프 출력\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    seq_model.save('test_model.h5')\n",
    "    \n",
    "    return history, seq_model\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "671a5950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: E:/군순/train/NIA_SL_SEN1247/NIA_SL_SEN1247_REAL03_L.mp4\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "NIA_SL_SEN1308 :  9.27%\n",
      "NIA_SL_SEN1245 :  8.73%\n",
      "NIA_SL_SEN1305 :  8.68%\n",
      "NIA_SL_SEN1041 :  8.21%\n",
      "NIA_SL_SEN1387 :  8.05%\n",
      "NIA_SL_SEN1247 :  7.91%\n",
      "NIA_SL_SEN1103 :  7.42%\n",
      "NIA_SL_SEN1854 :  6.89%\n",
      "NIA_SL_SEN1173 :  6.07%\n",
      "NIA_SL_SEN1032 :  5.91%\n",
      "NIA_SL_SEN1370 :  5.21%\n",
      "NIA_SL_SEN1376 :  5.02%\n",
      "NIA_SL_SEN1090 :  5.00%\n",
      "NIA_SL_SEN1881 :  3.90%\n",
      "NIA_SL_SEN1082 :  3.74%\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames, skeletons, hands):\n",
    "    num_frames = frames.shape[1]\n",
    "    video_length = min(MAX_SEQ_LENGTH, num_frames)\n",
    "\n",
    "    frame_mask = np.zeros((1, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros((1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "    frame_skeletons = np.zeros((1, MAX_SEQ_LENGTH, SKELETON_FEATURES), dtype=\"float32\")\n",
    "    frame_hands = np.zeros((1, MAX_SEQ_LENGTH, HAND_FEATURES), dtype=\"float32\")\n",
    "    frame_images = np.zeros((1, MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=\"float32\")\n",
    "    \n",
    "    feature_extractor = Sequential([\n",
    "        ResNet50(include_top=False, weights='imagenet', pooling='avg'),  # 예시로 평균 풀링 사용\n",
    "        Dense(NUM_FEATURES, activation='relu')  # NUM_FEATURES에 맞는 덴스 레이어 추가\n",
    "    ])\n",
    "    \n",
    "    for j in range(video_length):\n",
    "        # 이미지 데이터 전처리 및 특징 추출\n",
    "        image_feature = preprocess_image(frames[j:j+1])\n",
    "        image_feature = np.expand_dims(image_feature, axis=0)\n",
    "        feature_result = feature_extractor.predict(image_feature)\n",
    "\n",
    "        # frame_images 대신 feature_result를 사용\n",
    "        frame_features[0, j] = feature_result\n",
    "\n",
    "        # Mediapipe 데이터 전처리\n",
    "        skeleton_feature = preprocess_skeleton_data(skeletons[j])\n",
    "        hand_feature = preprocess_hand_data(hands[j])\n",
    "\n",
    "        frame_skeletons[0, j] = skeleton_feature\n",
    "        frame_hands[0, j] = hand_feature\n",
    "        frame_mask[0, j] = 1\n",
    "\n",
    "    return frame_features, frame_skeletons, frame_hands, frame_mask, frame_images\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    frames, skeletons, hands = load_video(path)    \n",
    "    try:\n",
    "        num_frames = frames.shape[1]\n",
    "    except IndexError:\n",
    "        print(\"Error: Unable to determine the number of frames. Frames shape:\", frames.shape)\n",
    "        return None\n",
    "    \n",
    "    frame_features, frame_skeletons, frame_hands, frame_mask, frame_images = prepare_single_video(frames, skeletons, hands)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_skeletons, frame_hands, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"{class_vocab[i]} : {probabilities[i] * 100:5.2f}%\")\n",
    "    \n",
    "    return frame_images\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0aabe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
