{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2750b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers, layers, models, regularizers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    GlobalAveragePooling1D,\n",
    "    LSTM, \n",
    "    Dense, \n",
    "    Input, \n",
    "    concatenate,\n",
    "    TimeDistributed,\n",
    "    Flatten\n",
    ")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6857ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "# 비디오 파일 목록과 태그를 포함하는 리스트를 만드는 함수\n",
    "def create_data_list(data_dir):\n",
    "    data_list = []\n",
    "    # data_dir 안의 각 디렉토리에 대해 반복\n",
    "    for item in os.listdir(data_dir):\n",
    "        item_path = os.path.join(data_dir, item)  # 아이템의 전체 경로\n",
    "        # 해당 경로가 디렉토리인지 확인\n",
    "        if os.path.isdir(item_path):\n",
    "            # 디렉토리 내의 모든 파일을 나열\n",
    "            for file_name in os.listdir(item_path):\n",
    "                # 파일이 .mp4 파일인지 확인\n",
    "                if file_name.endswith('.mp4'):\n",
    "                    # 리스트에 태그와 파일 경로를 추가\n",
    "                    data_list.append((item, str(data_dir+'/'+item)+'/'+file_name))\n",
    "    return data_list\n",
    "\n",
    "# 함수를 사용해서 리스트를 생성\n",
    "train_list = create_data_list(train_dir)\n",
    "test_list = create_data_list(test_dir)\n",
    "# 리스트에서 데이터프레임을 생성\n",
    "train_df = pd.DataFrame(data=train_list, columns=['tag', 'video_name'])\n",
    "test_df = pd.DataFrame(data=test_list, columns=['tag', 'video_name'])\n",
    "# 필요한 경우 열 순서를 수정\n",
    "train_df = train_df.loc[:, ['tag', 'video_name']]\n",
    "test_df = test_df.loc[:, ['tag', 'video_name']]\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "train_file_path = 'train.csv'\n",
    "test_file_path = 'test.csv'\n",
    "train_df.to_csv(train_file_path, encoding='utf-8-sig', index=False)\n",
    "test_df.to_csv(test_file_path, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1756281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total video for training: 50\n",
      "Total video for testing: 15\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(f\"Total video for training: {len(train_df)}\")\n",
    "print(f\"Total video for testing: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c4e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# GPU 장치 목록 가져오기\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    # GPU의 가상 메모리 제한을 6GB로 설정\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpu_devices[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 6)]\n",
    "    )\n",
    "    # set_memory_growth는 set_virtual_device_configuration과 함께 사용할 수 없습니다\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a9b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 256\n",
    "SKELETON_FEATURES = 33*4\n",
    "HAND_FEATURES = 21*3*2\n",
    "ARM_ANGLE_FEATURES = 2\n",
    "N_CLASSES = len(np.unique(train_df[\"tag\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b79c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 이미지에서 중앙에 맞춰 정사각형으로 잘나내는 함수\n",
    "def crop_center_square(frame):\n",
    "    # 이미지의 높이(y)와 너비(x)를 가져옴\n",
    "    y, x = frame.shape[0:2]\n",
    "    # 이미지의 높이와 너비 중 더 작은 값을 선택하여 정사각형의 크기를 결정\n",
    "    min_dim = min(y, x)\n",
    "    # 정사각형을 이미지 중앙에 위치시키기 위해 시작점의 x좌표와 y좌표를 계산\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    # 계산된 시작점과 정사각형의 크기를 이용하여 이미지의 중앙 부분을 잘라냅니다.\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2a39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    a = np.array([a.x, a.y])  # 첫 번째 점\n",
    "    b = np.array([b.x, b.y])  # 중간 점 (팔꿈치)\n",
    "    c = np.array([c.x, c.y])  # 세 번째 점 (손목)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f81fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일을 로드하고, 각 프레임을 처리하여 배열로 반환하는 함수\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, smooth_landmarks=True)\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "    # OpenCV를 사용하여 비디오 파일 열기\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    skeletons = []  # 스켈레톤 데이터\n",
    "    hand_landmarks = []  # 손 데이터\n",
    "    arm_angles = []  # 팔 각도 데이터\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # 비디오에서 프레임을 하나씩 읽기\n",
    "            ret, frame = cap.read()\n",
    "            # 읽을 프레임이 없으면 반복문을 종료\n",
    "            if not ret:\n",
    "                break\n",
    "            # 읽은 프레임에서 중앙의 정사각형 부분을 잘라냄\n",
    "            frame = crop_center_square(frame)\n",
    "            # 프레임의 크기를 지정된 크기로 조절\n",
    "            frame = cv2.resize(frame, resize)            \n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Mediapipe를 사용하여 스켈레톤 추출\n",
    "            hands_results = hands.process(frame_rgb)\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "           \n",
    "            if pose_results.pose_landmarks:\n",
    "                right_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "                right_elbow = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "                right_wrist = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "                left_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "                left_elbow = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "                left_wrist = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "\n",
    "                right_arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "                left_arm_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "\n",
    "                arm_angles.append((right_arm_angle, left_arm_angle))\n",
    "                skeletons.append(pose_results.pose_landmarks.landmark)\n",
    "                mp.solutions.drawing_utils.draw_landmarks(\n",
    "                    frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)            \n",
    "                \n",
    "            if hands_results.multi_hand_landmarks:\n",
    "                hand_landmarks_data = hands_results.multi_hand_landmarks\n",
    "                hand_landmarks.append(hand_landmarks_data)\n",
    "                for hand_lm in hand_landmarks_data:\n",
    "                    mp.solutions.drawing_utils.draw_landmarks(\n",
    "                        frame, hand_lm, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            cv2.imshow('Video Frame', frame)\n",
    "            cv2.waitKey(30)\n",
    "            # OpenCV는 BGR 색상 순서를 사용하므로, 이를 RGB 순서로 변경\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            # 처리된 프레임을 프레임 리스트에 추가\n",
    "            frames.append(frame)\n",
    "            # max_frames가 지정된 경우, 지정된 수의 프레임만큼만 처리\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        # 비디오 파일을 닫기\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        pose.close\n",
    "        hands.close\n",
    "    return np.array(frames), skeletons, hand_landmarks, np.array(arm_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "226bfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징추출\n",
    "def build_feature_extractor():\n",
    "    # 이미지 특징 추출을 위한 EfficientNetB0 모델\n",
    "    base_model = EfficientNetB0(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.efficientnet.preprocess_input\n",
    "    image_input = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed_image = preprocess_input(image_input)\n",
    "    image_features = base_model(preprocessed_image)\n",
    "\n",
    "    # Mediapipe 데이터 처리\n",
    "    mediapipe_input = keras.Input((258,))\n",
    "    mediapipe_features = keras.layers.Dense(258, activation=\"relu\")(mediapipe_input)\n",
    "    mediapipe_features = keras.layers.Dropout(0.3)(mediapipe_features)  # Dropout 추가\n",
    "\n",
    "    # 팔 각도 데이터 처리\n",
    "    arm_angle_input = keras.Input((2,))\n",
    "    arm_angle_features = keras.layers.Dense(16, activation=\"relu\")(arm_angle_input)\n",
    "    arm_angle_features = keras.layers.Dropout(0.3)(arm_angle_features)  # Dropout 추가\n",
    "\n",
    "    # 데이터 결합 및 추가 처리\n",
    "    combined_features = keras.layers.concatenate(\n",
    "        [image_features, mediapipe_features, arm_angle_features])\n",
    "    combined_features = keras.layers.BatchNormalization()(combined_features)\n",
    "    combined_features = keras.layers.Dense(\n",
    "        256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(combined_features)\n",
    "\n",
    "    return keras.Model(inputs=[image_input, mediapipe_input, arm_angle_input], outputs=combined_features, name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a307a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손 랜드마크를 2개로 제한한 코드\n",
    "def preprocess_skeleton_data(skeleton):\n",
    "    # 스켈레톤 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not skeleton:\n",
    "        return np.zeros(SKELETON_FEATURES)\n",
    "    # 스켈레톤 데이터를 1차원 배열로 변환\n",
    "    skeleton_array = np.array([[lm.x, lm.y, lm.z] for lm in skeleton]).flatten()    \n",
    "    # 부족한 부분을 0으로 채우기\n",
    "    skeleton_array = np.pad(skeleton_array, ((0, max(0, SKELETON_FEATURES - len(skeleton_array)))))    \n",
    "    return skeleton_array\n",
    "\n",
    "def preprocess_hand_data(hand_landmarks):\n",
    "    # 손 랜드마크 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not hand_landmarks or len(hand_landmarks) < 2:\n",
    "        return np.zeros(HAND_FEATURES)\n",
    "    \n",
    "    # 첫 번째와 두 번째 손에 대한 랜드마크만 처리\n",
    "    hand_data = []\n",
    "    for hand_lm in hand_landmarks[:2]:  # 첫 번째와 두 번째 손만 처리\n",
    "        lm_array = np.array([[lm.x, lm.y, lm.z] for lm in hand_lm.landmark]).flatten()\n",
    "        hand_data.extend(lm_array)\n",
    "\n",
    "    # 부족한 부분을 0으로 채우기\n",
    "    hand_data = np.pad(hand_data, ((0, max(0, HAND_FEATURES - len(hand_data)))))\n",
    "\n",
    "    return np.array(hand_data)\n",
    "\n",
    "def preprocess_arm_angle_data(arm_angles):\n",
    "    # 팔 각도 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not arm_angles.size == 0:\n",
    "        return np.zeros(2)  # 오른팔, 왼팔 각각의 각도\n",
    "    return np.array(arm_angles)\n",
    "\n",
    "def preprocess_image(frame):\n",
    "    # frame을 이미지 배열로 변환\n",
    "    frame = image.img_to_array(frame)\n",
    "    # EfficientNetB0에 맞는 전처리 적용\n",
    "    frame = preprocess_input(frame)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae3a9d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_all_video(df):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "\n",
    "    # Mediapipe 데이터를 저장할 배열 초기화                          \n",
    "    frame_skeletons = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, SKELETON_FEATURES), dtype=\"float32\")\n",
    "    frame_hands = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, HAND_FEATURES), dtype=\"float32\")    \n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "    frame_images = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=\"float32\")\n",
    "    frame_arm_angles = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, ARM_ANGLE_FEATURES), dtype=\"float32\")  # 2는 팔 각도 데이터 차원\n",
    "    \n",
    "    # 특징 추출기 모델 초기화\n",
    "    feature_extractor = build_feature_extractor()\n",
    "    \n",
    "    for idx, path in enumerate(video_paths):\n",
    "        frames, skeletons, hands, arm_angles = load_video(path)\n",
    "        video_length = min(MAX_SEQ_LENGTH, len(frames))\n",
    "\n",
    "        for i in range(video_length):\n",
    "            # 이미지 데이터 전처리 및 특징 추출\n",
    "            image_feature = preprocess_image(frames[i])\n",
    "            image_feature = np.expand_dims(image_feature, axis=0)\n",
    "                      \n",
    "            # Mediapipe 데이터 전처리\n",
    "            skeleton_feature = preprocess_skeleton_data(skeletons[i])\n",
    "            hand_feature = preprocess_hand_data(hands[i])\n",
    "            combined_mediapipe_data = np.concatenate([skeleton_feature, hand_feature])\n",
    "            combined_mediapipe_data = np.expand_dims(combined_mediapipe_data, axis=0)\n",
    "            \n",
    "            # 팔 각도 데이터 전처리\n",
    "            arm_angle_feature = preprocess_arm_angle_data(arm_angles[i])\n",
    "            arm_angle_feature = np.expand_dims(arm_angle_feature, axis=0)\n",
    "            \n",
    "            # 모델 예측\n",
    "            try:\n",
    "                # 특징 추출기 모델에 이미지, Mediapipe 데이터, 팔 각도 데이터 전달\n",
    "                frame_feature = feature_extractor.predict([image_feature, combined_mediapipe_data, arm_angle_feature], verbose=0)\n",
    "                frame_features[idx, i, :] = frame_feature.squeeze()  # 예측 결과 저장, .squeeze()로 불필요한 차원 제거\n",
    "            except Exception as e:\n",
    "                print(f\"Error during prediction at index {idx}, frame {i}: {e}\")\n",
    "                # 오류 발생시 해당 프레임을 0으로 설정하거나 다른 처리를 수행\n",
    "                frame_features[idx, i, :] = np.zeros(NUM_FEATURES)\n",
    "                frame_masks[idx, i] = 0  # 오류가 발생한 프레임은 마스크에서 제외\n",
    "            \n",
    "            # 데이터 저장\n",
    "            frame_images[idx, i, :] = frames[i]  # 원본 이미지 데이터 저장\n",
    "            frame_skeletons[idx, i, :] = skeleton_feature\n",
    "            frame_hands[idx, i, :] = hand_feature\n",
    "            frame_arm_angles[idx, i, :] = arm_angle_feature\n",
    "            frame_masks[idx, i] = 1\n",
    "            \n",
    "    # 반환 값에 Mediapipe 데이터 포함\n",
    "    return (frame_features, frame_skeletons, frame_hands, frame_arm_angles, frame_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8221829b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = prepare_all_video(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8144026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "train_labels = train_df[\"tag\"].values\n",
    "train_labels = train_label_processor(train_labels[..., None]).numpy()\n",
    "train_labels = np.squeeze(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65297a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = prepare_all_video(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "662e27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(test_df[\"tag\"]))\n",
    "test_labels = test_df[\"tag\"].values\n",
    "test_labels = test_label_processor(test_labels[..., None]).numpy()\n",
    "test_labels = np.squeeze(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0737a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 파일에 저장\n",
    "with open('train_data.pkl', 'wb') as file:\n",
    "    pickle.dump(train_data, file)\n",
    "with open('test_data.pkl', 'wb') as file:\n",
    "    pickle.dump(test_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a1de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data.pkl', 'rb') as file:\n",
    "    train_data = pickle.load(file)\n",
    "with open('test_data.pkl', 'rb') as file:\n",
    "    test_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "686df2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = train_label_processor.get_vocabulary()\n",
    "    \n",
    "    # 입력 레이어\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    skeleton_input = keras.Input((MAX_SEQ_LENGTH, SKELETON_FEATURES))\n",
    "    hand_input = keras.Input((MAX_SEQ_LENGTH, HAND_FEATURES))\n",
    "    arm_angle_input = keras.Input((MAX_SEQ_LENGTH, ARM_ANGLE_FEATURES))  # 팔 각도 데이터 입력 레이어\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    \n",
    "    # LSTM 레이어\n",
    "    x = LSTM(64, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = LSTM(32, return_sequences=False)(x)  # 시퀀스의 마지막 출력만 사용    \n",
    "\n",
    "    y_skeleton = GlobalAveragePooling1D()(skeleton_input)\n",
    "    y_hand = GlobalAveragePooling1D()(hand_input)\n",
    "    y_arm_angle = GlobalAveragePooling1D()(arm_angle_input)\n",
    "    \n",
    "    combined = concatenate([x, y_skeleton, y_hand, y_arm_angle])\n",
    "\n",
    "    # 추가 처리 및 출력 레이어\n",
    "    z = Dense(16, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(combined)\n",
    "    output = Dense(len(class_vocab), activation=\"softmax\", kernel_regularizer=regularizers.l2(0.01))(z)\n",
    "    \n",
    "    # 모델 생성 및 컴파일\n",
    "    lstm_model = keras.Model([frame_features_input, skeleton_input, hand_input, arm_angle_input, mask_input], output)\n",
    "    lstm_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c13067e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0420 - accuracy: 0.2222\n",
      "Epoch 1: val_loss improved from inf to 2.29023, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 12s 12s/step - loss: 2.0420 - accuracy: 0.2222 - val_loss: 2.2902 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9991 - accuracy: 0.2222\n",
      "Epoch 2: val_loss improved from 2.29023 to 2.28534, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.9991 - accuracy: 0.2222 - val_loss: 2.2853 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9667 - accuracy: 0.2222\n",
      "Epoch 3: val_loss improved from 2.28534 to 2.28039, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9667 - accuracy: 0.2222 - val_loss: 2.2804 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9475 - accuracy: 0.2444\n",
      "Epoch 4: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.9475 - accuracy: 0.2444 - val_loss: 2.3609 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9357 - accuracy: 0.2222\n",
      "Epoch 5: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9357 - accuracy: 0.2222 - val_loss: 2.4326 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9258 - accuracy: 0.2667\n",
      "Epoch 6: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9258 - accuracy: 0.2667 - val_loss: 2.4909 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9153 - accuracy: 0.2444\n",
      "Epoch 7: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.9153 - accuracy: 0.2444 - val_loss: 2.5063 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9063 - accuracy: 0.2444\n",
      "Epoch 8: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.9063 - accuracy: 0.2444 - val_loss: 2.5192 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8925 - accuracy: 0.2444\n",
      "Epoch 9: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8925 - accuracy: 0.2444 - val_loss: 2.5434 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8735 - accuracy: 0.3111\n",
      "Epoch 10: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.8735 - accuracy: 0.3111 - val_loss: 2.5052 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8515 - accuracy: 0.3556\n",
      "Epoch 11: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8515 - accuracy: 0.3556 - val_loss: 2.5444 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8308 - accuracy: 0.3778\n",
      "Epoch 12: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.8308 - accuracy: 0.3778 - val_loss: 2.5143 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8091 - accuracy: 0.4444\n",
      "Epoch 13: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.8091 - accuracy: 0.4444 - val_loss: 2.6902 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7909 - accuracy: 0.4000\n",
      "Epoch 14: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7909 - accuracy: 0.4000 - val_loss: 2.4740 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7712 - accuracy: 0.3778\n",
      "Epoch 15: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.7712 - accuracy: 0.3778 - val_loss: 2.5594 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7384 - accuracy: 0.4667\n",
      "Epoch 16: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7384 - accuracy: 0.4667 - val_loss: 2.8787 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7381 - accuracy: 0.3778\n",
      "Epoch 17: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.7381 - accuracy: 0.3778 - val_loss: 2.4667 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7037 - accuracy: 0.4000\n",
      "Epoch 18: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7037 - accuracy: 0.4000 - val_loss: 2.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6949 - accuracy: 0.3778\n",
      "Epoch 19: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.6949 - accuracy: 0.3778 - val_loss: 2.7623 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6497 - accuracy: 0.4444\n",
      "Epoch 20: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.6497 - accuracy: 0.4444 - val_loss: 3.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6488 - accuracy: 0.4444\n",
      "Epoch 21: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.6488 - accuracy: 0.4444 - val_loss: 2.8074 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6048 - accuracy: 0.4444\n",
      "Epoch 22: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.6048 - accuracy: 0.4444 - val_loss: 2.6076 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6048 - accuracy: 0.4000\n",
      "Epoch 23: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.6048 - accuracy: 0.4000 - val_loss: 2.8716 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5633 - accuracy: 0.4222\n",
      "Epoch 24: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.5633 - accuracy: 0.4222 - val_loss: 3.4502 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5571 - accuracy: 0.4444\n",
      "Epoch 25: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5571 - accuracy: 0.4444 - val_loss: 3.4198 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5169 - accuracy: 0.4222\n",
      "Epoch 26: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.5169 - accuracy: 0.4222 - val_loss: 3.2762 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4979 - accuracy: 0.4444\n",
      "Epoch 27: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4979 - accuracy: 0.4444 - val_loss: 3.5732 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4695 - accuracy: 0.4667\n",
      "Epoch 28: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4695 - accuracy: 0.4667 - val_loss: 3.7945 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4625 - accuracy: 0.4667\n",
      "Epoch 29: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4625 - accuracy: 0.4667 - val_loss: 3.3694 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4408 - accuracy: 0.4444\n",
      "Epoch 30: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4408 - accuracy: 0.4444 - val_loss: 3.7221 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4095 - accuracy: 0.4444\n",
      "Epoch 31: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4095 - accuracy: 0.4444 - val_loss: 4.0209 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3910 - accuracy: 0.4667\n",
      "Epoch 32: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3910 - accuracy: 0.4667 - val_loss: 4.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3990 - accuracy: 0.4667\n",
      "Epoch 33: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3990 - accuracy: 0.4667 - val_loss: 3.6099 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3619 - accuracy: 0.4444\n",
      "Epoch 34: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3619 - accuracy: 0.4444 - val_loss: 3.1063 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4542 - accuracy: 0.3778\n",
      "Epoch 35: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4542 - accuracy: 0.3778 - val_loss: 4.4008 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3211 - accuracy: 0.4889\n",
      "Epoch 36: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3211 - accuracy: 0.4889 - val_loss: 4.4989 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7875 - accuracy: 0.2889\n",
      "Epoch 37: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.7875 - accuracy: 0.2889 - val_loss: 3.9905 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2907 - accuracy: 0.4889\n",
      "Epoch 38: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2907 - accuracy: 0.4889 - val_loss: 2.6489 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6246 - accuracy: 0.3111\n",
      "Epoch 39: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.6246 - accuracy: 0.3111 - val_loss: 3.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3804 - accuracy: 0.4667\n",
      "Epoch 40: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3804 - accuracy: 0.4667 - val_loss: 3.9068 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2695 - accuracy: 0.5778\n",
      "Epoch 41: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2695 - accuracy: 0.5778 - val_loss: 4.4938 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3288 - accuracy: 0.5111\n",
      "Epoch 42: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3288 - accuracy: 0.5111 - val_loss: 4.6078 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3740 - accuracy: 0.4000\n",
      "Epoch 43: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3740 - accuracy: 0.4000 - val_loss: 4.4735 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2350 - accuracy: 0.5556\n",
      "Epoch 44: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2350 - accuracy: 0.5556 - val_loss: 3.9739 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2485 - accuracy: 0.4889\n",
      "Epoch 45: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2485 - accuracy: 0.4889 - val_loss: 3.7005 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2890 - accuracy: 0.5333\n",
      "Epoch 46: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2890 - accuracy: 0.5333 - val_loss: 3.5115 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2963 - accuracy: 0.5111\n",
      "Epoch 47: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2963 - accuracy: 0.5111 - val_loss: 3.6027 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2682 - accuracy: 0.6000\n",
      "Epoch 48: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2682 - accuracy: 0.6000 - val_loss: 3.8259 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2418 - accuracy: 0.5778\n",
      "Epoch 49: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2418 - accuracy: 0.5778 - val_loss: 4.1513 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2277 - accuracy: 0.5333\n",
      "Epoch 50: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2277 - accuracy: 0.5333 - val_loss: 3.8467 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1883 - accuracy: 0.5556\n",
      "Epoch 51: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1883 - accuracy: 0.5556 - val_loss: 3.6633 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1739 - accuracy: 0.5556\n",
      "Epoch 52: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1739 - accuracy: 0.5556 - val_loss: 3.7281 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1613 - accuracy: 0.5556\n",
      "Epoch 53: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1613 - accuracy: 0.5556 - val_loss: 3.8759 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1447 - accuracy: 0.5556\n",
      "Epoch 54: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1447 - accuracy: 0.5556 - val_loss: 4.0823 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1335 - accuracy: 0.6000\n",
      "Epoch 55: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1335 - accuracy: 0.6000 - val_loss: 4.2334 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1172 - accuracy: 0.6000\n",
      "Epoch 56: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1172 - accuracy: 0.6000 - val_loss: 4.2302 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0987 - accuracy: 0.6000\n",
      "Epoch 57: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0987 - accuracy: 0.6000 - val_loss: 4.1998 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0863 - accuracy: 0.5556\n",
      "Epoch 58: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0863 - accuracy: 0.5556 - val_loss: 4.2767 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0724 - accuracy: 0.6667\n",
      "Epoch 59: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0724 - accuracy: 0.6667 - val_loss: 4.5362 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0534 - accuracy: 0.6889\n",
      "Epoch 60: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0534 - accuracy: 0.6889 - val_loss: 4.8944 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0368 - accuracy: 0.6444\n",
      "Epoch 61: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0368 - accuracy: 0.6444 - val_loss: 4.9436 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0220 - accuracy: 0.6444\n",
      "Epoch 62: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0220 - accuracy: 0.6444 - val_loss: 4.7531 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.6444\n",
      "Epoch 63: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0073 - accuracy: 0.6444 - val_loss: 4.4671 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9954 - accuracy: 0.6889\n",
      "Epoch 64: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9954 - accuracy: 0.6889 - val_loss: 4.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9801 - accuracy: 0.6889\n",
      "Epoch 65: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9801 - accuracy: 0.6889 - val_loss: 4.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9645 - accuracy: 0.7111\n",
      "Epoch 66: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9645 - accuracy: 0.7111 - val_loss: 4.4520 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9495 - accuracy: 0.7333\n",
      "Epoch 67: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9495 - accuracy: 0.7333 - val_loss: 4.4271 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9350 - accuracy: 0.7556\n",
      "Epoch 68: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9350 - accuracy: 0.7556 - val_loss: 4.4264 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9196 - accuracy: 0.7778\n",
      "Epoch 69: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9196 - accuracy: 0.7778 - val_loss: 4.5019 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9015 - accuracy: 0.7778\n",
      "Epoch 70: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9015 - accuracy: 0.7778 - val_loss: 4.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8794 - accuracy: 0.8000\n",
      "Epoch 71: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8794 - accuracy: 0.8000 - val_loss: 4.7223 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8638 - accuracy: 0.8000\n",
      "Epoch 72: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8638 - accuracy: 0.8000 - val_loss: 4.5351 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8485 - accuracy: 0.7778\n",
      "Epoch 73: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8485 - accuracy: 0.7778 - val_loss: 4.6792 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8236 - accuracy: 0.8222\n",
      "Epoch 74: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8236 - accuracy: 0.8222 - val_loss: 4.6817 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8075 - accuracy: 0.8000\n",
      "Epoch 75: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8075 - accuracy: 0.8000 - val_loss: 4.4899 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8019 - accuracy: 0.8444\n",
      "Epoch 76: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8019 - accuracy: 0.8444 - val_loss: 4.5992 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7642 - accuracy: 0.8444\n",
      "Epoch 77: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7642 - accuracy: 0.8444 - val_loss: 4.6417 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7627 - accuracy: 0.8444\n",
      "Epoch 78: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7627 - accuracy: 0.8444 - val_loss: 4.3779 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7481 - accuracy: 0.8444\n",
      "Epoch 79: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7481 - accuracy: 0.8444 - val_loss: 4.4602 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7245 - accuracy: 0.8444\n",
      "Epoch 80: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7245 - accuracy: 0.8444 - val_loss: 4.6147 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7032 - accuracy: 0.8889\n",
      "Epoch 81: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7032 - accuracy: 0.8889 - val_loss: 4.6138 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.9111\n",
      "Epoch 82: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6828 - accuracy: 0.9111 - val_loss: 4.5610 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.9111\n",
      "Epoch 83: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6672 - accuracy: 0.9111 - val_loss: 4.5856 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6481 - accuracy: 0.9111\n",
      "Epoch 84: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6481 - accuracy: 0.9111 - val_loss: 4.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.9333\n",
      "Epoch 85: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6331 - accuracy: 0.9333 - val_loss: 4.7701 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.9556\n",
      "Epoch 86: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6182 - accuracy: 0.9556 - val_loss: 4.8592 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.9556\n",
      "Epoch 87: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6015 - accuracy: 0.9556 - val_loss: 4.9325 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5870 - accuracy: 0.9556\n",
      "Epoch 88: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5870 - accuracy: 0.9556 - val_loss: 5.0931 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.9778\n",
      "Epoch 89: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5698 - accuracy: 0.9778 - val_loss: 5.0884 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5554 - accuracy: 1.0000\n",
      "Epoch 90: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5554 - accuracy: 1.0000 - val_loss: 4.9494 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5352 - accuracy: 1.0000\n",
      "Epoch 91: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5352 - accuracy: 1.0000 - val_loss: 4.9842 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 1.0000\n",
      "Epoch 92: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5213 - accuracy: 1.0000 - val_loss: 5.0969 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 1.0000\n",
      "Epoch 93: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5076 - accuracy: 1.0000 - val_loss: 5.1009 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 1.0000\n",
      "Epoch 94: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4942 - accuracy: 1.0000 - val_loss: 5.0214 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 1.0000\n",
      "Epoch 95: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4810 - accuracy: 1.0000 - val_loss: 4.9503 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 1.0000\n",
      "Epoch 96: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4696 - accuracy: 1.0000 - val_loss: 4.9721 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 1.0000\n",
      "Epoch 97: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4580 - accuracy: 1.0000 - val_loss: 5.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4466 - accuracy: 1.0000\n",
      "Epoch 98: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4466 - accuracy: 1.0000 - val_loss: 5.1388 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 1.0000\n",
      "Epoch 99: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4350 - accuracy: 1.0000 - val_loss: 5.1605 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 1.0000\n",
      "Epoch 100: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4232 - accuracy: 1.0000 - val_loss: 5.1863 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 1.0000\n",
      "Epoch 101: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4114 - accuracy: 1.0000 - val_loss: 5.2454 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 1.0000\n",
      "Epoch 102: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4008 - accuracy: 1.0000 - val_loss: 5.2506 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 1.0000\n",
      "Epoch 103: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3901 - accuracy: 1.0000 - val_loss: 5.2664 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 1.0000\n",
      "Epoch 104: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3808 - accuracy: 1.0000 - val_loss: 5.2768 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 1.0000\n",
      "Epoch 105: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3718 - accuracy: 1.0000 - val_loss: 5.3668 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 1.0000\n",
      "Epoch 106: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3631 - accuracy: 1.0000 - val_loss: 5.4649 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 1.0000\n",
      "Epoch 107: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3547 - accuracy: 1.0000 - val_loss: 5.5317 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3472 - accuracy: 1.0000\n",
      "Epoch 108: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3472 - accuracy: 1.0000 - val_loss: 5.5803 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 1.0000\n",
      "Epoch 109: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3397 - accuracy: 1.0000 - val_loss: 5.6200 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 1.0000\n",
      "Epoch 110: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3327 - accuracy: 1.0000 - val_loss: 5.6601 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3260 - accuracy: 1.0000\n",
      "Epoch 111: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3260 - accuracy: 1.0000 - val_loss: 5.6812 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 1.0000\n",
      "Epoch 112: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3197 - accuracy: 1.0000 - val_loss: 5.7133 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 1.0000\n",
      "Epoch 113: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3137 - accuracy: 1.0000 - val_loss: 5.7592 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3078 - accuracy: 1.0000\n",
      "Epoch 114: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3078 - accuracy: 1.0000 - val_loss: 5.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 1.0000\n",
      "Epoch 115: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3021 - accuracy: 1.0000 - val_loss: 5.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 1.0000\n",
      "Epoch 116: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2965 - accuracy: 1.0000 - val_loss: 5.8632 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 1.0000\n",
      "Epoch 117: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2913 - accuracy: 1.0000 - val_loss: 5.8951 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 1.0000\n",
      "Epoch 118: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2864 - accuracy: 1.0000 - val_loss: 5.9381 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 1.0000\n",
      "Epoch 119: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2818 - accuracy: 1.0000 - val_loss: 5.9728 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 1.0000\n",
      "Epoch 120: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2775 - accuracy: 1.0000 - val_loss: 5.9811 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 1.0000\n",
      "Epoch 121: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2733 - accuracy: 1.0000 - val_loss: 5.9997 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 1.0000\n",
      "Epoch 122: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2694 - accuracy: 1.0000 - val_loss: 6.0446 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 1.0000\n",
      "Epoch 123: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2656 - accuracy: 1.0000 - val_loss: 6.0934 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 1.0000\n",
      "Epoch 124: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2619 - accuracy: 1.0000 - val_loss: 6.1163 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 1.0000\n",
      "Epoch 125: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2585 - accuracy: 1.0000 - val_loss: 6.1156 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 1.0000\n",
      "Epoch 126: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2552 - accuracy: 1.0000 - val_loss: 6.1155 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 1.0000\n",
      "Epoch 127: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2521 - accuracy: 1.0000 - val_loss: 6.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 1.0000\n",
      "Epoch 128: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2492 - accuracy: 1.0000 - val_loss: 6.1835 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 1.0000\n",
      "Epoch 129: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2464 - accuracy: 1.0000 - val_loss: 6.2298 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 1.0000\n",
      "Epoch 130: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2437 - accuracy: 1.0000 - val_loss: 6.2627 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 1.0000\n",
      "Epoch 131: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2412 - accuracy: 1.0000 - val_loss: 6.2871 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2388 - accuracy: 1.0000\n",
      "Epoch 132: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2388 - accuracy: 1.0000 - val_loss: 6.3047 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 1.0000\n",
      "Epoch 133: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2365 - accuracy: 1.0000 - val_loss: 6.3184 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 1.0000\n",
      "Epoch 134: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2343 - accuracy: 1.0000 - val_loss: 6.3301 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 1.0000\n",
      "Epoch 135: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2322 - accuracy: 1.0000 - val_loss: 6.3377 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 1.0000\n",
      "Epoch 136: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2302 - accuracy: 1.0000 - val_loss: 6.3412 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 1.0000\n",
      "Epoch 137: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2283 - accuracy: 1.0000 - val_loss: 6.3476 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 1.0000\n",
      "Epoch 138: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2265 - accuracy: 1.0000 - val_loss: 6.3662 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 1.0000\n",
      "Epoch 139: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2247 - accuracy: 1.0000 - val_loss: 6.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 1.0000\n",
      "Epoch 140: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2231 - accuracy: 1.0000 - val_loss: 6.4193 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 1.0000\n",
      "Epoch 141: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2215 - accuracy: 1.0000 - val_loss: 6.4430 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 1.0000\n",
      "Epoch 142: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2199 - accuracy: 1.0000 - val_loss: 6.4566 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 1.0000\n",
      "Epoch 143: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2185 - accuracy: 1.0000 - val_loss: 6.4610 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 1.0000\n",
      "Epoch 144: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2171 - accuracy: 1.0000 - val_loss: 6.4589 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 1.0000\n",
      "Epoch 145: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2157 - accuracy: 1.0000 - val_loss: 6.4541 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 1.0000\n",
      "Epoch 146: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2144 - accuracy: 1.0000 - val_loss: 6.4488 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 1.0000\n",
      "Epoch 147: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2131 - accuracy: 1.0000 - val_loss: 6.4475 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 1.0000\n",
      "Epoch 148: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2119 - accuracy: 1.0000 - val_loss: 6.4447 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 1.0000\n",
      "Epoch 149: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2108 - accuracy: 1.0000 - val_loss: 6.4425 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 1.0000\n",
      "Epoch 150: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2096 - accuracy: 1.0000 - val_loss: 6.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 1.0000\n",
      "Epoch 151: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2085 - accuracy: 1.0000 - val_loss: 6.4426 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 1.0000\n",
      "Epoch 152: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2075 - accuracy: 1.0000 - val_loss: 6.4444 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 1.0000\n",
      "Epoch 153: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2064 - accuracy: 1.0000 - val_loss: 6.4467 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 1.0000\n",
      "Epoch 154: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2054 - accuracy: 1.0000 - val_loss: 6.4490 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 1.0000\n",
      "Epoch 155: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2044 - accuracy: 1.0000 - val_loss: 6.4516 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 1.0000\n",
      "Epoch 156: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2035 - accuracy: 1.0000 - val_loss: 6.4546 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2025 - accuracy: 1.0000\n",
      "Epoch 157: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2025 - accuracy: 1.0000 - val_loss: 6.4578 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 1.0000\n",
      "Epoch 158: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2016 - accuracy: 1.0000 - val_loss: 6.4623 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 1.0000\n",
      "Epoch 159: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2007 - accuracy: 1.0000 - val_loss: 6.4660 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1998 - accuracy: 1.0000\n",
      "Epoch 160: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1998 - accuracy: 1.0000 - val_loss: 6.4686 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 1.0000\n",
      "Epoch 161: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1990 - accuracy: 1.0000 - val_loss: 6.4738 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 1.0000\n",
      "Epoch 162: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1981 - accuracy: 1.0000 - val_loss: 6.4829 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 1.0000\n",
      "Epoch 163: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1973 - accuracy: 1.0000 - val_loss: 6.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 1.0000\n",
      "Epoch 164: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1965 - accuracy: 1.0000 - val_loss: 6.5041 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 1.0000\n",
      "Epoch 165: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1957 - accuracy: 1.0000 - val_loss: 6.5135 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 1.0000\n",
      "Epoch 166: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1950 - accuracy: 1.0000 - val_loss: 6.5209 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 1.0000\n",
      "Epoch 167: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1942 - accuracy: 1.0000 - val_loss: 6.5258 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 1.0000\n",
      "Epoch 168: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1935 - accuracy: 1.0000 - val_loss: 6.5279 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 1.0000\n",
      "Epoch 169: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1928 - accuracy: 1.0000 - val_loss: 6.5280 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1921 - accuracy: 1.0000\n",
      "Epoch 170: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1921 - accuracy: 1.0000 - val_loss: 6.5266 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 1.0000\n",
      "Epoch 171: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1914 - accuracy: 1.0000 - val_loss: 6.5249 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 1.0000\n",
      "Epoch 172: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1907 - accuracy: 1.0000 - val_loss: 6.5239 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 1.0000\n",
      "Epoch 173: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1901 - accuracy: 1.0000 - val_loss: 6.5244 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 1.0000\n",
      "Epoch 174: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1894 - accuracy: 1.0000 - val_loss: 6.5263 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 1.0000\n",
      "Epoch 175: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1888 - accuracy: 1.0000 - val_loss: 6.5286 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 1.0000\n",
      "Epoch 176: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1881 - accuracy: 1.0000 - val_loss: 6.5313 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 1.0000\n",
      "Epoch 177: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1875 - accuracy: 1.0000 - val_loss: 6.5332 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 1.0000\n",
      "Epoch 178: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1869 - accuracy: 1.0000 - val_loss: 6.5345 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 1.0000\n",
      "Epoch 179: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1863 - accuracy: 1.0000 - val_loss: 6.5371 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 1.0000\n",
      "Epoch 180: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1857 - accuracy: 1.0000 - val_loss: 6.5418 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 1.0000\n",
      "Epoch 181: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1852 - accuracy: 1.0000 - val_loss: 6.5465 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 1.0000\n",
      "Epoch 182: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1846 - accuracy: 1.0000 - val_loss: 6.5504 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 1.0000\n",
      "Epoch 183: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1840 - accuracy: 1.0000 - val_loss: 6.5530 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 1.0000\n",
      "Epoch 184: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1835 - accuracy: 1.0000 - val_loss: 6.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 1.0000\n",
      "Epoch 185: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1829 - accuracy: 1.0000 - val_loss: 6.5575 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 1.0000\n",
      "Epoch 186: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1824 - accuracy: 1.0000 - val_loss: 6.5598 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 1.0000\n",
      "Epoch 187: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1819 - accuracy: 1.0000 - val_loss: 6.5603 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 1.0000\n",
      "Epoch 188: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1814 - accuracy: 1.0000 - val_loss: 6.5595 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 1.0000\n",
      "Epoch 189: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1808 - accuracy: 1.0000 - val_loss: 6.5571 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 1.0000\n",
      "Epoch 190: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1803 - accuracy: 1.0000 - val_loss: 6.5529 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 1.0000\n",
      "Epoch 191: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1798 - accuracy: 1.0000 - val_loss: 6.5475 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 1.0000\n",
      "Epoch 192: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1793 - accuracy: 1.0000 - val_loss: 6.5408 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 1.0000\n",
      "Epoch 193: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1788 - accuracy: 1.0000 - val_loss: 6.5344 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 1.0000\n",
      "Epoch 194: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1783 - accuracy: 1.0000 - val_loss: 6.5335 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 1.0000\n",
      "Epoch 195: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1778 - accuracy: 1.0000 - val_loss: 6.5438 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 1.0000\n",
      "Epoch 196: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1774 - accuracy: 1.0000 - val_loss: 6.5635 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 1.0000\n",
      "Epoch 197: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1769 - accuracy: 1.0000 - val_loss: 6.5841 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 1.0000\n",
      "Epoch 198: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1764 - accuracy: 1.0000 - val_loss: 6.5971 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 1.0000\n",
      "Epoch 199: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1760 - accuracy: 1.0000 - val_loss: 6.6020 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 1.0000\n",
      "Epoch 200: val_loss did not improve from 2.28039\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1755 - accuracy: 1.0000 - val_loss: 6.5955 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0041 - accuracy: 0.2000\n",
      "Test accuracy: 20.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE= 64\n",
    "def run_experiment():\n",
    "    filepath = \"tmp/video_classifier_lstm.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    # 모델 학습\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1], train_data[2], train_data[3], train_data[4]],\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.1,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    \n",
    "    # 테스트 데이터에 대한 평가\n",
    "    _, accuracy = seq_model.evaluate(\n",
    "        [test_data[0], test_data[1], test_data[2], test_data[3], test_data[4]],\n",
    "        test_labels\n",
    "    )\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    \n",
    "    # 손실 및 정확도 그래프 출력\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    # 손실 그래프\n",
    "    ax1 = plt.subplot(1, 1, 1)\n",
    "    ax1.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', color='blue', linestyle='dashed')\n",
    "    ax1.set_title('Training and Validation Loss and Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax1.legend(loc='upper left')\n",
    "    # 정확도 그래프를 같은 그래프에 추가\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(history.history['accuracy'], label='Train Accuracy', color='green')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green', linestyle='dashed')\n",
    "    ax2.set_ylabel('Accuracy', color='green')\n",
    "    ax2.tick_params(axis='y', labelcolor='green')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    seq_model.save('lstm_model.h5')\n",
    "    \n",
    "    return history, seq_model\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "671a5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_video(frames, skeletons, hands, arm_angles):\n",
    "    num_frames = len(frames)\n",
    "    video_length = min(MAX_SEQ_LENGTH, num_frames)\n",
    "\n",
    "    # 데이터 초기화\n",
    "    frame_mask = np.zeros((1, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros((1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "    frame_skeletons = np.zeros((1, MAX_SEQ_LENGTH, SKELETON_FEATURES), dtype=\"float32\")\n",
    "    frame_hands = np.zeros((1, MAX_SEQ_LENGTH, HAND_FEATURES), dtype=\"float32\")\n",
    "    frame_arm_angles = np.zeros((1, MAX_SEQ_LENGTH, ARM_ANGLE_FEATURES), dtype=\"float32\")\n",
    "    \n",
    "    # EfficientNetB0 모델을 사용하여 이미지 특징 추출\n",
    "    feature_extractor = Sequential([\n",
    "        EfficientNetB0(include_top=False, weights='imagenet', pooling='avg'),\n",
    "        Dense(NUM_FEATURES, activation='relu')\n",
    "    ])\n",
    "    \n",
    "    for j in range(video_length):\n",
    "        # 이미지 데이터 전처리 및 특징 추출\n",
    "        image_feature = preprocess_image(frames[j])\n",
    "        image_feature = np.expand_dims(image_feature, axis=0)\n",
    "        feature_result = feature_extractor.predict(image_feature)\n",
    "\n",
    "        # 특징 저장\n",
    "        frame_features[0, j] = feature_result\n",
    "\n",
    "        # Mediapipe 데이터 전처리\n",
    "        skeleton_feature = preprocess_skeleton_data(skeletons[j])\n",
    "        hand_feature = preprocess_hand_data(hands[j])        \n",
    "        arm_angle_feature = np.array(arm_angles[j])\n",
    "\n",
    "        # 데이터 저장\n",
    "        frame_skeletons[0, j] = skeleton_feature\n",
    "        frame_hands[0, j] = hand_feature\n",
    "        frame_mask[0, j] = 1        \n",
    "        frame_arm_angles[0, j] = arm_angle_feature\n",
    "\n",
    "    return frame_features, frame_skeletons, frame_hands, frame_mask, frame_arm_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57a5d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_prediction(path, sequence_model):\n",
    "    class_vocab = test_label_processor.get_vocabulary()\n",
    "    frames, skeletons, hands, arm_angles = load_video(path)    \n",
    "    try:\n",
    "        num_frames = len(frames)\n",
    "    except IndexError:\n",
    "        print(\"Error: Unable to determine the number of frames. Frames shape:\", frames.shape)\n",
    "        return None\n",
    "    \n",
    "    # EfficientNetB0 모델을 사용하여 프레임에서 특징 추출\n",
    "    frame_features, frame_skeletons, frame_hands, frame_mask, frame_arm_angles = prepare_single_video(frames, skeletons, hands, arm_angles)\n",
    "    \n",
    "    # LSTM 모델을 사용하여 예측 수행\n",
    "    probabilities = sequence_model.predict([frame_features, frame_skeletons, frame_hands, frame_arm_angles, frame_mask])[0]\n",
    "    \n",
    "    # 가장 가능성 높은 레이블 출력\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"{class_vocab[i]} : {probabilities[i] * 100:5.2f}%\")\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73081774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: data/test/NIA_SL_SEN0203/NIA_SL_SEN0203_REAL13_F.mp4\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "NIA_SL_SEN0159 : 82.23%\n",
      "NIA_SL_SEN0275 : 17.76%\n",
      "NIA_SL_SEN0011 :  0.01%\n",
      "NIA_SL_SEN0013 :  0.00%\n",
      "NIA_SL_SEN0203 :  0.00%\n"
     ]
    }
   ],
   "source": [
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video,sequence_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdfe2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
