{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69661b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = open('log2.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb65178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0e80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 장치 목록 가져오기\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    # GPU의 가상 메모리 제한을 6GB로 설정\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpu_devices[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 6)]\n",
    "    )\n",
    "    # set_memory_growth는 set_virtual_device_configuration과 함께 사용할 수 없습니다\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32e0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "# 비디오 파일 목록과 태그를 포함하는 리스트를 만드는 함수\n",
    "def create_data_list(data_dir):\n",
    "    data_list = []\n",
    "    # data_dir 안의 각 디렉토리에 대해 반복\n",
    "    for item in os.listdir(data_dir):\n",
    "        item_path = os.path.join(data_dir, item)  # 아이템의 전체 경로\n",
    "        # 해당 경로가 디렉토리인지 확인\n",
    "        if os.path.isdir(item_path):\n",
    "            # 디렉토리 내의 모든 파일을 나열\n",
    "            for file_name in os.listdir(item_path):\n",
    "                # 파일이 .mp4 파일인지 확인\n",
    "                if file_name.endswith('.mp4'):\n",
    "                    # 리스트에 태그와 파일 경로를 추가\n",
    "                    data_list.append((item, str(data_dir+'/'+item)+'/'+file_name))\n",
    "    return data_list\n",
    "\n",
    "# 함수를 사용해서 리스트를 생성\n",
    "train_list = create_data_list(train_dir)\n",
    "test_list = create_data_list(test_dir)\n",
    "# 리스트에서 데이터프레임을 생성\n",
    "train_df = pd.DataFrame(data=train_list, columns=['tag', 'video_name'])\n",
    "test_df = pd.DataFrame(data=test_list, columns=['tag', 'video_name'])\n",
    "# 필요한 경우 열 순서를 수정\n",
    "train_df = train_df.loc[:, ['tag', 'video_name']]\n",
    "test_df = test_df.loc[:, ['tag', 'video_name']]\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "train_file_path = 'train.csv'\n",
    "test_file_path = 'test.csv'\n",
    "train_df.to_csv(train_file_path, encoding='utf-8-sig', index=False)\n",
    "test_df.to_csv(test_file_path, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d9c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(f\"Total video for training: {len(train_df)}\")\n",
    "print(f\"Total video for testing: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3205a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "\n",
    "MAX_SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9094e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨링\n",
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "labels = train_df[\"tag\"].values\n",
    "labels = label_processor(labels[..., None]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a2a402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 이미지에서 중앙에 맞춰 정사각형으로 잘라내는 함수\n",
    "def crop_center_square(frame):\n",
    "    # 이미지의 높이(y)와 너비(x)를 가져옴\n",
    "    y, x = frame.shape[0:2]\n",
    "    # 이미지의 높이와 너비 중 더 작은 값을 선택하여 정사각형의 크기를 결정\n",
    "    min_dim = min(y, x)\n",
    "    # 정사각형을 이미지 중앙에 위치시키기 위해 시작점의 x좌표와 y좌표를 계산\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    # 계산된 시작점과 정사각형의 크기를 이용하여 이미지의 중앙 부분 잘라내기\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8d0f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각도 계산\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array([a.x, a.y])  # 첫 번째 점\n",
    "    b = np.array([b.x, b.y])  # 중간 점\n",
    "    c = np.array([c.x, c.y])  # 세 번째 점\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2088865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손가락의 각도를 계산하는 함수\n",
    "def calculate_finger_angles(hand_landmarks, mp_hands):\n",
    "    angles = []\n",
    "    for finger in [mp_hands.HandLandmark.THUMB_CMC, mp_hands.HandLandmark.INDEX_FINGER_MCP, mp_hands.HandLandmark.MIDDLE_FINGER_MCP,\n",
    "                   mp_hands.HandLandmark.RING_FINGER_MCP, mp_hands.HandLandmark.PINKY_MCP]:\n",
    "        if finger == mp_hands.HandLandmark.THUMB_CMC:\n",
    "            # 엄지는 다른 손가락과 구조가 다름\n",
    "            base = np.array([hand_landmarks.landmark[finger].x, hand_landmarks.landmark[finger].y])\n",
    "            tip = np.array([hand_landmarks.landmark[finger + 2].x, hand_landmarks.landmark[finger + 2].y])\n",
    "        else:\n",
    "            base = np.array([hand_landmarks.landmark[finger].x, hand_landmarks.landmark[finger].y])\n",
    "            tip = np.array([hand_landmarks.landmark[finger + 3].x, hand_landmarks.landmark[finger + 3].y])\n",
    "        angle = np.arccos(np.dot(base, tip) / (np.linalg.norm(base) * np.linalg.norm(tip)))\n",
    "        angles.append(np.degrees(angle))\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac67868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 팔 각도 계산 함수\n",
    "def calculate_arm_angle(pose_landmarks, mp_pose, side):\n",
    "    if side == 'Right':\n",
    "        shoulder = pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "        elbow = pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "        wrist = pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "    else:\n",
    "        shoulder = pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "        elbow = pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "        wrist = pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "\n",
    "    return calculate_angle([shoulder.x, shoulder.y], [elbow.x, elbow.y], [wrist.x, wrist.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec3c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일을 로드하고, 각 프레임을 처리하여 배열로 반환하는 함수\n",
    "def load_video(path, max_frames=0):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_pose = mp.solutions.pose\n",
    "    \n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=2, min_detection_confidence=0.3, smooth_landmarks=True)\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, model_complexity=2, min_detection_confidence=0.3)\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    finger_angles = []  # 손가락 각도 데이터\n",
    "    arm_angles = []  # 팔 각도 데이터\n",
    "\n",
    "    try:\n",
    "        while True:            \n",
    "            ret, frame = cap.read() # 비디오에서 프레임을 하나씩 읽기            \n",
    "            if not ret:\n",
    "                break # 읽을 프레임이 없으면 반복문을 종료\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            hands_results = hands.process(frame_rgb)\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "           \n",
    "            if pose_results.pose_landmarks:\n",
    "                # 팔 각도 계산\n",
    "                right_arm_angle = calculate_arm_angle(pose_results.pose_landmarks, mp_pose, 'Right')\n",
    "                left_arm_angle = calculate_arm_angle(pose_results.pose_landmarks, mp_pose, 'Left')\n",
    "                arm_angles.append((right_arm_angle, left_arm_angle))\n",
    "\n",
    "            if hands_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hands_results.multi_hand_landmarks:\n",
    "                    angles = calculate_finger_angles(hand_landmarks, mp_hands)\n",
    "                    finger_angles.append(angles)\n",
    "\n",
    "            if len(finger_angles) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        pose.close()\n",
    "        hands.close()\n",
    "\n",
    "    return np.array(arm_angles), np.array(finger_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5a26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_arm_angle_data(arm_angles):\n",
    "    # 팔 각도 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not arm_angles:\n",
    "        return np.zeros(2)  # 오른팔, 왼팔 각각의 각도\n",
    "    return np.array(arm_angles)\n",
    "\n",
    "def preprocess_hand_data(hand_landmarks, mp_hands):\n",
    "    # 손 랜드마크 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not hand_landmarks or len(hand_landmarks) < 2:\n",
    "        return np.zeros(10)\n",
    "    \n",
    "    hand_angles = []\n",
    "\n",
    "    for hand_lm in hand_landmarks[:2]:  # 첫 번째와 두 번째 손만 처리\n",
    "        angles = calculate_finger_angles(hand_lm, mp_hands)\n",
    "        hand_angles.extend(angles)\n",
    "\n",
    "    # 부족한 부분을 0으로 채우기\n",
    "    hand_angles = np.pad(hand_angles, (0, max(0, 10 - len(hand_angles))))\n",
    "\n",
    "    return np.array(hand_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a52744df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_video(df):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "\n",
    "    # 팔 각도 데이터와 손가락 각도 데이터 저장할 배열 초기화\n",
    "    frame_arm_angles = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, 4), dtype=\"float16\")  # 왼팔, 오른팔 각도\n",
    "    frame_hand_angles = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, 10), dtype=\"float16\")  # 손가락 각도\n",
    "    \n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # load_video 함수 수정 필요 (이미지와 스켈레톤 데이터 제외하고, 팔 각도와 손가락 각도만 반환)\n",
    "        arm_angles, hand_landmarks = load_video(path)\n",
    "        video_length = min(MAX_SEQ_LENGTH, len(arm_angles))\n",
    "\n",
    "        for i in range(video_length):\n",
    "            # 팔 각도 데이터 전처리\n",
    "            arm_angle_feature = preprocess_arm_angle_data(arm_angles[i])\n",
    "            frame_arm_angles[idx, i, :] = arm_angle_feature\n",
    "\n",
    "            # 손가락 각도 데이터 전처리\n",
    "            hand_angle_feature = preprocess_hand_data(hand_landmarks[i], mp_hands)\n",
    "            frame_hand_angles[idx, i, :] = hand_angle_feature\n",
    "\n",
    "            frame_masks[idx, i] = 1\n",
    "            \n",
    "    # 반환 값에 팔 각도 및 손가락 각도 데이터 포함\n",
    "    return (frame_arm_angles, frame_hand_angles, frame_masks), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50482a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # INFO 메시지를 숨긴다.\n",
    "tf.get_logger().setLevel('ERROR')         # TensorFlow 로그를 ERROR 레벨로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bdfa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = prepare_all_video(train_df)\n",
    "test_data, test_labels = prepare_all_video(test_df)\n",
    "train_labels = np.squeeze(train_labels)\n",
    "test_labels = np.squeeze(test_labels)\n",
    "\n",
    "sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180846a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    \n",
    "    # 팔 각도 및 손가락 각도 데이터에 대한 입력\n",
    "    arm_angle_input = keras.Input((MAX_SEQ_LENGTH, 4))  # 왼팔, 오른팔 각도 (각 2개의 값)\n",
    "    hand_input = keras.Input((MAX_SEQ_LENGTH, 10))  # 손가락 각도\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    \n",
    "    # LSTM 레이어 처리\n",
    "    x_arm_angle = LSTM(64, return_sequences=True)(arm_angle_input, mask=mask_input)\n",
    "    x_arm_angle = LSTM(32, return_sequences=True)(x_arm_angle)\n",
    "    x_arm_angle = GlobalAveragePooling1D()(x_arm_angle)\n",
    "\n",
    "    x_hand = LSTM(64, return_sequences=True)(hand_input, mask=mask_input)\n",
    "    x_hand = LSTM(32, return_sequences=True)(x_hand)\n",
    "    x_hand = GlobalAveragePooling1D()(x_hand)\n",
    "    \n",
    "    # 데이터 결합\n",
    "    combined = concatenate([x_arm_angle, x_hand])\n",
    "\n",
    "    # 추가 처리\n",
    "    z = Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(combined)\n",
    "    z = Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(z)\n",
    "    output = Dense(len(class_vocab), activation=\"softmax\", kernel_regularizer=regularizers.l2(0.01))(z)\n",
    "\n",
    "    # 모델 생성 및 컴파일\n",
    "    lstm_model = keras.Model([arm_angle_input, hand_input, mask_input], output)\n",
    "    lstm_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE= 128\n",
    "def run_experiment():\n",
    "    filepath = \"tmp/video_classifier_lstm3.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1], train_data[2]],  # 팔 각도, 손가락 각도, 마스크 데이터\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    \n",
    "    _, accuracy = seq_model.evaluate(\n",
    "        [test_data[0], test_data[1], test_data[2]],  # 팔 각도, 손가락 각도, 마스크 데이터\n",
    "        test_labels\n",
    "    )\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    \n",
    "    # 손실 및 정확도 그래프 출력\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    # 손실 그래프\n",
    "    ax1 = plt.subplot(1, 1, 1)\n",
    "    ax1.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', color='blue', linestyle='dashed')\n",
    "    ax1.set_title('Training and Validation Loss and Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax1.legend(loc='upper left')\n",
    "    # 정확도 그래프를 같은 그래프에 추가\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(history.history['accuracy'], label='Train Accuracy', color='green')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green', linestyle='dashed')\n",
    "    ax2.set_ylabel('Accuracy', color='green')\n",
    "    ax2.tick_params(axis='y', labelcolor='green')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    seq_model.save('test_lstm_model3.h5')\n",
    "    \n",
    "    return history, seq_model\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888051e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_video(hands, arm_angles):\n",
    "    frame_mask = np.zeros((1, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_hand_angles = np.zeros((1, MAX_SEQ_LENGTH, HAND_FEATURES), dtype=\"float16\")\n",
    "    frame_arm_angles = np.zeros((1, MAX_SEQ_LENGTH, 4), dtype=\"float16\")  # 4는 왼팔, 오른팔 각도\n",
    "    \n",
    "    for j in range(MAX_SEQ_LENGTH):\n",
    "        # 손가락 각도 데이터 전처리\n",
    "        hand_feature = preprocess_hand_data(hands[j]) if j < len(hands) else np.zeros(HAND_FEATURES)\n",
    "        frame_hand_angles[0, j] = hand_feature\n",
    "\n",
    "        # 팔 각도 데이터 전처리\n",
    "        arm_angle_feature = np.array(arm_angles[j]) if j < len(arm_angles) else np.zeros(4)\n",
    "        frame_arm_angles[0, j] = arm_angle_feature\n",
    "\n",
    "        frame_mask[0, j] = 1 if j < len(hands) or j < len(arm_angles) else 0\n",
    "\n",
    "    return frame_hand_angles, frame_arm_angles, frame_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e13ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    hands, arm_angles = load_video(path)\n",
    "    \n",
    "    frame_hand_angles, frame_arm_angles, frame_mask = prepare_single_video(hands, arm_angles)\n",
    "    probabilities = sequence_model.predict([frame_hand_angles, frame_arm_angles, frame_mask])[0]\n",
    "    \n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"{class_vocab[i]} : {probabilities[i] * 100:5.2f}%\")\n",
    "        \n",
    "    return probabilities  # 클래스별 예측 확률 반환\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ce7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f9577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89be0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
