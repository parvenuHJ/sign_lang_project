{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccba677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = open('log2.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2750b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Bidirectional, \n",
    "    LSTM, \n",
    "    GlobalAveragePooling1D, \n",
    "    Dense, \n",
    "    Input, \n",
    "    concatenate,\n",
    "    TimeDistributed,\n",
    "    Flatten\n",
    ")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac6857ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "# 비디오 파일 목록과 태그를 포함하는 리스트를 만드는 함수\n",
    "def create_data_list(data_dir):\n",
    "    data_list = []\n",
    "    # data_dir 안의 각 디렉토리에 대해 반복\n",
    "    for item in os.listdir(data_dir):\n",
    "        item_path = os.path.join(data_dir, item)  # 아이템의 전체 경로\n",
    "        # 해당 경로가 디렉토리인지 확인\n",
    "        if os.path.isdir(item_path):\n",
    "            # 디렉토리 내의 모든 파일을 나열\n",
    "            for file_name in os.listdir(item_path):\n",
    "                # 파일이 .mp4 파일인지 확인\n",
    "                if file_name.endswith('.mp4'):\n",
    "                    # 리스트에 태그와 파일 경로를 추가\n",
    "                    data_list.append((item, str(data_dir+'/'+item)+'/'+file_name))\n",
    "    return data_list\n",
    "\n",
    "# 함수를 사용해서 리스트를 생성\n",
    "train_list = create_data_list(train_dir)\n",
    "test_list = create_data_list(test_dir)\n",
    "# 리스트에서 데이터프레임을 생성\n",
    "train_df = pd.DataFrame(data=train_list, columns=['tag', 'video_name'])\n",
    "test_df = pd.DataFrame(data=test_list, columns=['tag', 'video_name'])\n",
    "# 필요한 경우 열 순서를 수정\n",
    "train_df = train_df.loc[:, ['tag', 'video_name']]\n",
    "test_df = test_df.loc[:, ['tag', 'video_name']]\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "train_file_path = 'train.csv'\n",
    "test_file_path = 'test.csv'\n",
    "train_df.to_csv(train_file_path, encoding='utf-8-sig', index=False)\n",
    "test_df.to_csv(test_file_path, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1756281",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(f\"Total video for training: {len(train_df)}\")\n",
    "print(f\"Total video for testing: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c4e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 장치 목록 가져오기\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    # GPU의 가상 메모리 제한을 6GB로 설정\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpu_devices[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 6)]\n",
    "    )\n",
    "    # set_memory_growth는 set_virtual_device_configuration과 함께 사용할 수 없습니다\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a9b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 500\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048\n",
    "SKELETON_FEATURES = 33*4\n",
    "HAND_FEATURES = 21*3*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b79c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 이미지에서 중앙에 맞춰 정사각형으로 잘나내는 함수\n",
    "def crop_center_square(frame):\n",
    "    # 이미지의 높이(y)와 너비(x)를 가져옴\n",
    "    y, x = frame.shape[0:2]\n",
    "    # 이미지의 높이와 너비 중 더 작은 값을 선택하여 정사각형의 크기를 결정\n",
    "    min_dim = min(y, x)\n",
    "    # 정사각형을 이미지 중앙에 위치시키기 위해 시작점의 x좌표와 y좌표를 계산\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    # 계산된 시작점과 정사각형의 크기를 이용하여 이미지의 중앙 부분을 잘라냅니다.\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2a39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    a = np.array([a.x, a.y])  # 첫 번째 점\n",
    "    b = np.array([b.x, b.y])  # 중간 점 (팔꿈치)\n",
    "    c = np.array([c.x, c.y])  # 세 번째 점 (손목)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2f81fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일을 로드하고, 각 프레임을 처리하여 배열로 반환하는 함수\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, smooth_landmarks=True)\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "    # OpenCV를 사용하여 비디오 파일 열기\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    skeletons = []  # 스켈레톤 데이터\n",
    "    hand_landmarks = []  # 손 데이터\n",
    "    arm_angles = []  # 팔 각도 데이터\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # 비디오에서 프레임을 하나씩 읽기\n",
    "            ret, frame = cap.read()\n",
    "            # 읽을 프레임이 없으면 반복문을 종료\n",
    "            if not ret:\n",
    "                break\n",
    "            # 읽은 프레임에서 중앙의 정사각형 부분을 잘라냄\n",
    "            frame = crop_center_square(frame)\n",
    "            # 프레임의 크기를 지정된 크기로 조절\n",
    "            frame = cv2.resize(frame, resize)            \n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Mediapipe를 사용하여 스켈레톤 추출\n",
    "            hands_results = hands.process(frame_rgb)\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "           \n",
    "            if pose_results.pose_landmarks:\n",
    "                right_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "                right_elbow = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "                right_wrist = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "                left_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "                left_elbow = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "                left_wrist = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "\n",
    "                right_arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "                left_arm_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "\n",
    "                arm_angles.append((right_arm_angle, left_arm_angle))\n",
    "                skeletons.append(pose_results.pose_landmarks.landmark)\n",
    "                mp.solutions.drawing_utils.draw_landmarks(\n",
    "                    frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)            \n",
    "                \n",
    "            if hands_results.multi_hand_landmarks:\n",
    "                hand_landmarks_data = hands_results.multi_hand_landmarks\n",
    "                hand_landmarks.append(hand_landmarks_data)\n",
    "                for hand_lm in hand_landmarks_data:\n",
    "                    mp.solutions.drawing_utils.draw_landmarks(\n",
    "                        frame, hand_lm, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            cv2.imshow('Video Frame', frame)\n",
    "            cv2.waitKey(30)\n",
    "            # OpenCV는 BGR 색상 순서를 사용하므로, 이를 RGB 순서로 변경\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            # 처리된 프레임을 프레임 리스트에 추가\n",
    "            frames.append(frame)\n",
    "            # max_frames가 지정된 경우, 지정된 수의 프레임만큼만 처리\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        # 비디오 파일을 닫기\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        pose.close\n",
    "        hands.close\n",
    "    return np.array(frames), skeletons, hand_landmarks, np.array(arm_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "226bfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징추출\n",
    "def build_feature_extractor():\n",
    "    # 이미지 특징 추출을 위한 InceptionV3 모델\n",
    "    base_model = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    image_input = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed_image = preprocess_input(image_input)\n",
    "    image_features = base_model(preprocessed_image)\n",
    "\n",
    "    # Mediapipe 데이터 처리\n",
    "    mediapipe_input = keras.Input((258,))\n",
    "    mediapipe_features = keras.layers.Dense(258, activation=\"relu\")(mediapipe_input)\n",
    "    mediapipe_features = keras.layers.Dropout(0.5)(mediapipe_features)  # Dropout 추가\n",
    "\n",
    "    # 팔 각도 데이터 처리\n",
    "    arm_angle_input = keras.Input((2,))\n",
    "    arm_angle_features = keras.layers.Dense(16, activation=\"relu\")(arm_angle_input)\n",
    "    arm_angle_features = keras.layers.Dropout(0.5)(arm_angle_features)  # Dropout 추가\n",
    "\n",
    "    # 데이터 결합 및 추가 처리\n",
    "    combined_features = keras.layers.concatenate([image_features, mediapipe_features, arm_angle_features])\n",
    "    combined_features = keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(combined_features)  # 정규화 추가\n",
    "\n",
    "    # 최종 출력 레이어\n",
    "    outputs = keras.layers.Dense(5, activation=\"softmax\")(combined_features)  # 클래스 수에 맞게 조정\n",
    "\n",
    "    return keras.Model(inputs=[image_input, mediapipe_input, arm_angle_input], outputs=outputs, name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a307a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손 랜드마크를 2개로 제한한 코드\n",
    "def preprocess_skeleton_data(skeleton):\n",
    "    # 스켈레톤 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not skeleton:\n",
    "        return np.zeros(SKELETON_FEATURES)\n",
    "    # 스켈레톤 데이터를 1차원 배열로 변환\n",
    "    skeleton_array = np.array([[lm.x, lm.y, lm.z] for lm in skeleton]).flatten()    \n",
    "    # 부족한 부분을 0으로 채우기\n",
    "    skeleton_array = np.pad(skeleton_array, ((0, max(0, SKELETON_FEATURES - len(skeleton_array)))))    \n",
    "    return skeleton_array\n",
    "\n",
    "def preprocess_hand_data(hand_landmarks):\n",
    "    # 손 랜드마크 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not hand_landmarks or len(hand_landmarks) < 2:\n",
    "        return np.zeros(HAND_FEATURES)\n",
    "    \n",
    "    # 첫 번째와 두 번째 손에 대한 랜드마크만 처리\n",
    "    hand_data = []\n",
    "    for hand_lm in hand_landmarks[:2]:  # 첫 번째와 두 번째 손만 처리\n",
    "        lm_array = np.array([[lm.x, lm.y, lm.z] for lm in hand_lm.landmark]).flatten()\n",
    "        hand_data.extend(lm_array)\n",
    "\n",
    "    # 부족한 부분을 0으로 채우기\n",
    "    hand_data = np.pad(hand_data, ((0, max(0, HAND_FEATURES - len(hand_data)))))\n",
    "\n",
    "    return np.array(hand_data)\n",
    "\n",
    "def preprocess_arm_angle_data(arm_angles):\n",
    "    # 팔 각도 데이터가 없는 경우 빈 벡터 반환\n",
    "    if not arm_angles:\n",
    "        return np.zeros(2)  # 오른팔, 왼팔 각각의 각도\n",
    "    return np.array(arm_angles)\n",
    "\n",
    "def preprocess_image(frame):    \n",
    "    frame = image.img_to_array(frame[0])  # frame[0]으로 변경\n",
    "    frame = preprocess_input(frame)  # ResNet50의 전처리 함수를 사용하여 정규화\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae3a9d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_all_video(df):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "\n",
    "    # Mediapipe 데이터를 저장할 배열 초기화                          \n",
    "    frame_skeletons = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, SKELETON_FEATURES), dtype=\"float16\")\n",
    "    frame_hands = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, HAND_FEATURES), dtype=\"float16\")\n",
    "    \n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float16\")\n",
    "    \n",
    "    # 이미지 데이터 저장할 배열 초기화\n",
    "    frame_images = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=\"float16\")\n",
    "    # 팔 각도 데이터 저장할 배열 초기화\n",
    "    frame_arm_angles = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, 2), dtype=\"float16\")  # 2는 팔 각도 데이터 차원\n",
    "    \n",
    "    # 특징 추출기 모델 초기화\n",
    "    feature_extractor = build_feature_extractor()\n",
    "\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        frames, skeletons, hands, arm_angles = load_video(path)\n",
    "        video_length = min(MAX_SEQ_LENGTH, len(frames))\n",
    "\n",
    "        for i in range(video_length):\n",
    "            # 이미지 데이터 전처리 및 특징 추출\n",
    "            image_feature = preprocess_image(frames[i:i+1])\n",
    "            image_feature = np.expand_dims(image_feature, axis=0)  # 차원 확장\n",
    "                      \n",
    "            # Mediapipe 데이터 전처리\n",
    "            skeleton_feature = preprocess_skeleton_data(skeletons[i])\n",
    "            hand_feature = preprocess_hand_data(hands[i])\n",
    "            combined_mediapipe_data = np.concatenate([skeleton_feature, hand_feature])\n",
    "            combined_mediapipe_data = np.expand_dims(combined_mediapipe_data, axis=0)\n",
    "            \n",
    "            # 팔 각도 데이터 전처리\n",
    "            arm_angle_feature = np.array(arm_angles[i])\n",
    "            arm_angle_feature = np.expand_dims(arm_angle_feature, axis=0)\n",
    "            \n",
    "            # 모델 예측\n",
    "            try:\n",
    "                # feature_extractor에 모든 데이터 전달\n",
    "                frame_feature = feature_extractor.predict([image_feature, combined_mediapipe_data, arm_angle_feature], verbose=0)\n",
    "                frame_features[idx, i, :] = frame_feature  # 데이터 저장\n",
    "            except Exception as e:\n",
    "                print(\"Error during prediction:\", e)\n",
    "            \n",
    "            # 데이터 저장\n",
    "            frame_images[idx, i, :] = frames[i]  # 원본 이미지 데이터 저장\n",
    "            frame_skeletons[idx, i, :] = skeleton_feature\n",
    "            frame_hands[idx, i, :] = hand_feature\n",
    "            frame_arm_angles[idx, i, :] = arm_angle_feature\n",
    "            frame_masks[idx, i] = 1\n",
    "            \n",
    "    # 반환 값에 Mediapipe 데이터 포함\n",
    "    return (frame_features, frame_skeletons, frame_hands, frame_arm_angles, frame_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d332bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # INFO 메시지를 숨긴다.\n",
    "tf.get_logger().setLevel('ERROR')         # TensorFlow 로그를 ERROR 레벨로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8221829b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n",
      "Error during prediction: could not broadcast input array from shape (5,) into shape (2048,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data, train_labels \u001b[38;5;241m=\u001b[39m prepare_all_video(train_df)\n\u001b[0;32m      2\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(train_labels)\n\u001b[0;32m      4\u001b[0m test_data, test_labels \u001b[38;5;241m=\u001b[39m prepare_all_video(test_df)\n",
      "Cell \u001b[1;32mIn[13], line 42\u001b[0m, in \u001b[0;36mprepare_all_video\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 모델 예측\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# feature_extractor에 모든 데이터 전달\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     frame_feature \u001b[38;5;241m=\u001b[39m feature_extractor\u001b[38;5;241m.\u001b[39mpredict([image_feature, combined_mediapipe_data, arm_angle_feature], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     43\u001b[0m     frame_features[idx, i, :] \u001b[38;5;241m=\u001b[39m frame_feature  \u001b[38;5;66;03m# 데이터 저장\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2655\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2654\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2655\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function(iterator)\n\u001b[0;32m   2656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2657\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    878\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    879\u001b[0m )\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = prepare_all_video(train_df)\n",
    "\n",
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "train_labels = train_df[\"tag\"].values\n",
    "train_labels = label_processor(labels[..., None]).numpy()\n",
    "train_labels = np.squeeze(train_labels)\n",
    "sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65297a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = prepare_all_video(test_df)\n",
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(test_df[\"tag\"]))\n",
    "test_labels = test_df[\"tag\"].values\n",
    "test_labels = label_processor(labels[..., None]).numpy()\n",
    "test_labels = np.squeeze(test_labels)\n",
    "sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "617610e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    \n",
    "    # 기존 이미지 특징에 대한 입력\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    skeleton_input = keras.Input((MAX_SEQ_LENGTH, SKELETON_FEATURES))\n",
    "    hand_input = keras.Input((MAX_SEQ_LENGTH, HAND_FEATURES))\n",
    "    arm_angle_input = keras.Input((MAX_SEQ_LENGTH, 2))  # 팔 각도 데이터 입력 레이어\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    \n",
    "    # LSTM 레이어 처리\n",
    "    x = LSTM(64, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Mediapipe 데이터 처리\n",
    "    y_skeleton = GlobalAveragePooling1D()(skeleton_input)\n",
    "    y_hand = GlobalAveragePooling1D()(hand_input)\n",
    "\n",
    "    # 팔 각도 데이터 처리\n",
    "    y_arm_angle = GlobalAveragePooling1D()(arm_angle_input)\n",
    "\n",
    "    # 데이터 결합\n",
    "    combined = concatenate([x, y_skeleton, y_hand, y_arm_angle])\n",
    "\n",
    "    # 추가 처리\n",
    "    z = Dense(16, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(combined)\n",
    "    output = Dense(len(class_vocab), activation=\"softmax\", kernel_regularizer=regularizers.l2(0.01))(z)\n",
    "    \n",
    "    # 모델 생성 및 컴파일\n",
    "    lstm_model = keras.Model([frame_features_input, skeleton_input, hand_input, arm_angle_input, mask_input], output)\n",
    "    lstm_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c13067e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 27.6522 - accuracy: 0.2564\n",
      "Epoch 1: val_loss improved from inf to 19.74641, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 12s 12s/step - loss: 27.6522 - accuracy: 0.2564 - val_loss: 19.7464 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 26.5577 - accuracy: 0.2564\n",
      "Epoch 2: val_loss improved from 19.74641 to 18.66704, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 26.5577 - accuracy: 0.2564 - val_loss: 18.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 25.4716 - accuracy: 0.2564\n",
      "Epoch 3: val_loss improved from 18.66704 to 17.58889, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 25.4716 - accuracy: 0.2564 - val_loss: 17.5889 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 24.3908 - accuracy: 0.2564\n",
      "Epoch 4: val_loss improved from 17.58889 to 16.51308, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 24.3908 - accuracy: 0.2564 - val_loss: 16.5131 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 23.3158 - accuracy: 0.2564\n",
      "Epoch 5: val_loss improved from 16.51308 to 15.44020, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 23.3158 - accuracy: 0.2564 - val_loss: 15.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.2468 - accuracy: 0.2564\n",
      "Epoch 6: val_loss improved from 15.44020 to 14.37050, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 22.2468 - accuracy: 0.2564 - val_loss: 14.3705 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.1837 - accuracy: 0.2564\n",
      "Epoch 7: val_loss improved from 14.37050 to 13.30405, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 21.1837 - accuracy: 0.2564 - val_loss: 13.3040 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.1263 - accuracy: 0.2564\n",
      "Epoch 8: val_loss improved from 13.30405 to 12.24075, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 20.1263 - accuracy: 0.2564 - val_loss: 12.2407 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.0742 - accuracy: 0.2564\n",
      "Epoch 9: val_loss improved from 12.24075 to 11.18059, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.0742 - accuracy: 0.2564 - val_loss: 11.1806 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.0270 - accuracy: 0.2564\n",
      "Epoch 10: val_loss improved from 11.18059 to 10.12422, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 18.0270 - accuracy: 0.2564 - val_loss: 10.1242 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.9839 - accuracy: 0.2564\n",
      "Epoch 11: val_loss improved from 10.12422 to 9.07411, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 16.9839 - accuracy: 0.2564 - val_loss: 9.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 15.9444 - accuracy: 0.2564\n",
      "Epoch 12: val_loss improved from 9.07411 to 8.03369, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 15.9444 - accuracy: 0.2564 - val_loss: 8.0337 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.9075 - accuracy: 0.2564\n",
      "Epoch 13: val_loss improved from 8.03369 to 7.06660, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 14.9075 - accuracy: 0.2564 - val_loss: 7.0666 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8820 - accuracy: 0.2564\n",
      "Epoch 14: val_loss improved from 7.06660 to 6.26484, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 13.8820 - accuracy: 0.2564 - val_loss: 6.2648 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.8925 - accuracy: 0.2564\n",
      "Epoch 15: val_loss improved from 6.26484 to 5.52694, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 12.8925 - accuracy: 0.2564 - val_loss: 5.5269 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.9183 - accuracy: 0.2564\n",
      "Epoch 16: val_loss improved from 5.52694 to 4.81875, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 11.9183 - accuracy: 0.2564 - val_loss: 4.8188 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9730 - accuracy: 0.2564\n",
      "Epoch 17: val_loss improved from 4.81875 to 4.17572, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10.9730 - accuracy: 0.2564 - val_loss: 4.1757 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1165 - accuracy: 0.2564\n",
      "Epoch 18: val_loss improved from 4.17572 to 3.67342, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 10.1165 - accuracy: 0.2564 - val_loss: 3.6734 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4559 - accuracy: 0.2564\n",
      "Epoch 19: val_loss improved from 3.67342 to 3.36107, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.4559 - accuracy: 0.2564 - val_loss: 3.3611 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.0491 - accuracy: 0.2564\n",
      "Epoch 20: val_loss improved from 3.36107 to 3.19030, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 9.0491 - accuracy: 0.2564 - val_loss: 3.1903 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.8071 - accuracy: 0.2564\n",
      "Epoch 21: val_loss improved from 3.19030 to 3.11081, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.8071 - accuracy: 0.2564 - val_loss: 3.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6239 - accuracy: 0.2564\n",
      "Epoch 22: val_loss improved from 3.11081 to 3.05773, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.6239 - accuracy: 0.2564 - val_loss: 3.0577 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4286 - accuracy: 0.2564\n",
      "Epoch 23: val_loss improved from 3.05773 to 3.00109, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.4286 - accuracy: 0.2564 - val_loss: 3.0011 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.1932 - accuracy: 0.2564\n",
      "Epoch 24: val_loss improved from 3.00109 to 2.93038, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.1932 - accuracy: 0.2564 - val_loss: 2.9304 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9110 - accuracy: 0.2564\n",
      "Epoch 25: val_loss improved from 2.93038 to 2.84370, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 7.9110 - accuracy: 0.2564 - val_loss: 2.8437 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 7.5837 - accuracy: 0.2564\n",
      "Epoch 26: val_loss improved from 2.84370 to 2.74284, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 7.5837 - accuracy: 0.2564 - val_loss: 2.7428 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.2163 - accuracy: 0.2564\n",
      "Epoch 27: val_loss improved from 2.74284 to 2.63130, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 7.2163 - accuracy: 0.2564 - val_loss: 2.6313 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8152 - accuracy: 0.2564\n",
      "Epoch 28: val_loss improved from 2.63130 to 2.51356, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 6.8152 - accuracy: 0.2564 - val_loss: 2.5136 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3871 - accuracy: 0.2564\n",
      "Epoch 29: val_loss improved from 2.51356 to 2.39480, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 6.3871 - accuracy: 0.2564 - val_loss: 2.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9389 - accuracy: 0.2564\n",
      "Epoch 30: val_loss improved from 2.39480 to 2.28102, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.9389 - accuracy: 0.2564 - val_loss: 2.2810 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.4784 - accuracy: 0.2564\n",
      "Epoch 31: val_loss improved from 2.28102 to 2.17916, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.4784 - accuracy: 0.2564 - val_loss: 2.1792 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0138 - accuracy: 0.2564\n",
      "Epoch 32: val_loss improved from 2.17916 to 2.09712, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.0138 - accuracy: 0.2564 - val_loss: 2.0971 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5549 - accuracy: 0.2564\n",
      "Epoch 33: val_loss improved from 2.09712 to 2.04329, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.5549 - accuracy: 0.2564 - val_loss: 2.0433 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1121 - accuracy: 0.2564\n",
      "Epoch 34: val_loss improved from 2.04329 to 2.02505, saving model to tmp\\video_classifier_lstm.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.1121 - accuracy: 0.2564 - val_loss: 2.0250 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6960 - accuracy: 0.2308\n",
      "Epoch 35: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.6960 - accuracy: 0.2308 - val_loss: 2.0462 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3143 - accuracy: 0.2564\n",
      "Epoch 36: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.3143 - accuracy: 0.2564 - val_loss: 2.1049 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9709 - accuracy: 0.2564\n",
      "Epoch 37: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.9709 - accuracy: 0.2564 - val_loss: 2.1955 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6659 - accuracy: 0.2564\n",
      "Epoch 38: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.6659 - accuracy: 0.2564 - val_loss: 2.3145 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4022 - accuracy: 0.2564\n",
      "Epoch 39: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.4022 - accuracy: 0.2564 - val_loss: 2.4699 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1928 - accuracy: 0.2564\n",
      "Epoch 40: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.1928 - accuracy: 0.2564 - val_loss: 2.6764 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0611 - accuracy: 0.2821\n",
      "Epoch 41: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.0611 - accuracy: 0.2821 - val_loss: 2.9460 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0205 - accuracy: 0.2821\n",
      "Epoch 42: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.0205 - accuracy: 0.2821 - val_loss: 3.2452 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0446 - accuracy: 0.2564\n",
      "Epoch 43: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.0446 - accuracy: 0.2564 - val_loss: 3.5338 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0879 - accuracy: 0.2564\n",
      "Epoch 44: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0879 - accuracy: 0.2564 - val_loss: 3.7816 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1168 - accuracy: 0.2564\n",
      "Epoch 45: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.1168 - accuracy: 0.2564 - val_loss: 3.9728 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1210 - accuracy: 0.2564\n",
      "Epoch 46: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.1210 - accuracy: 0.2564 - val_loss: 4.1205 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1091 - accuracy: 0.2564\n",
      "Epoch 47: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.1091 - accuracy: 0.2564 - val_loss: 4.2448 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0961 - accuracy: 0.2564\n",
      "Epoch 48: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.0961 - accuracy: 0.2564 - val_loss: 4.3590 - val_accuracy: 0.1000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0933 - accuracy: 0.2564\n",
      "Epoch 49: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.0933 - accuracy: 0.2564 - val_loss: 4.4651 - val_accuracy: 0.1000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1009 - accuracy: 0.2308\n",
      "Epoch 50: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1009 - accuracy: 0.2308 - val_loss: 4.5517 - val_accuracy: 0.1000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1075 - accuracy: 0.2308\n",
      "Epoch 51: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.1075 - accuracy: 0.2308 - val_loss: 4.6064 - val_accuracy: 0.1000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0989 - accuracy: 0.2308\n",
      "Epoch 52: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.0989 - accuracy: 0.2308 - val_loss: 4.6226 - val_accuracy: 0.1000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0675 - accuracy: 0.2308\n",
      "Epoch 53: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.0675 - accuracy: 0.2308 - val_loss: 4.6032 - val_accuracy: 0.1000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0143 - accuracy: 0.2308\n",
      "Epoch 54: val_loss did not improve from 2.02505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 2.0143 - accuracy: 0.2308 - val_loss: 4.5574 - val_accuracy: 0.1000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9475 - accuracy: 0.2308\n",
      "Epoch 55: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.9475 - accuracy: 0.2308 - val_loss: 4.4981 - val_accuracy: 0.1000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8787 - accuracy: 0.2051\n",
      "Epoch 56: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.8787 - accuracy: 0.2051 - val_loss: 4.4370 - val_accuracy: 0.1000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8184 - accuracy: 0.2308\n",
      "Epoch 57: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.8184 - accuracy: 0.2308 - val_loss: 4.3811 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7735 - accuracy: 0.2564\n",
      "Epoch 58: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7735 - accuracy: 0.2564 - val_loss: 4.3324 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7454 - accuracy: 0.2821\n",
      "Epoch 59: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7454 - accuracy: 0.2821 - val_loss: 4.2885 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7308 - accuracy: 0.2564\n",
      "Epoch 60: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7308 - accuracy: 0.2564 - val_loss: 4.2452 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7244 - accuracy: 0.2564\n",
      "Epoch 61: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7244 - accuracy: 0.2564 - val_loss: 4.1993 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7216 - accuracy: 0.2564\n",
      "Epoch 62: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7216 - accuracy: 0.2564 - val_loss: 4.1494 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7189 - accuracy: 0.2564\n",
      "Epoch 63: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7189 - accuracy: 0.2564 - val_loss: 4.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7151 - accuracy: 0.2564\n",
      "Epoch 64: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7151 - accuracy: 0.2564 - val_loss: 4.0417 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7100 - accuracy: 0.2564\n",
      "Epoch 65: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.7100 - accuracy: 0.2564 - val_loss: 3.9888 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7042 - accuracy: 0.2821\n",
      "Epoch 66: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7042 - accuracy: 0.2821 - val_loss: 3.9403 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6983 - accuracy: 0.2821\n",
      "Epoch 67: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6983 - accuracy: 0.2821 - val_loss: 3.8988 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6931 - accuracy: 0.2821\n",
      "Epoch 68: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6931 - accuracy: 0.2821 - val_loss: 3.8658 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6887 - accuracy: 0.2308\n",
      "Epoch 69: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6887 - accuracy: 0.2308 - val_loss: 3.8425 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6849 - accuracy: 0.2308\n",
      "Epoch 70: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6849 - accuracy: 0.2308 - val_loss: 3.8293 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6816 - accuracy: 0.2308\n",
      "Epoch 71: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6816 - accuracy: 0.2308 - val_loss: 3.8261 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6783 - accuracy: 0.2308\n",
      "Epoch 72: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6783 - accuracy: 0.2308 - val_loss: 3.8326 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6748 - accuracy: 0.2308\n",
      "Epoch 73: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6748 - accuracy: 0.2308 - val_loss: 3.8481 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6709 - accuracy: 0.2051\n",
      "Epoch 74: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6709 - accuracy: 0.2051 - val_loss: 3.8721 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6667 - accuracy: 0.2051\n",
      "Epoch 75: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6667 - accuracy: 0.2051 - val_loss: 3.9036 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6624 - accuracy: 0.2564\n",
      "Epoch 76: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6624 - accuracy: 0.2564 - val_loss: 3.9419 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6580 - accuracy: 0.2564\n",
      "Epoch 77: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6580 - accuracy: 0.2564 - val_loss: 3.9860 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6537 - accuracy: 0.2821\n",
      "Epoch 78: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6537 - accuracy: 0.2821 - val_loss: 4.0346 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6497 - accuracy: 0.2821\n",
      "Epoch 79: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6497 - accuracy: 0.2821 - val_loss: 4.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6458 - accuracy: 0.2564\n",
      "Epoch 80: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6458 - accuracy: 0.2564 - val_loss: 4.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6420 - accuracy: 0.2821\n",
      "Epoch 81: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6420 - accuracy: 0.2821 - val_loss: 4.1954 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6383 - accuracy: 0.2308\n",
      "Epoch 82: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6383 - accuracy: 0.2308 - val_loss: 4.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6347 - accuracy: 0.1795\n",
      "Epoch 83: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6347 - accuracy: 0.1795 - val_loss: 4.3034 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6311 - accuracy: 0.1795\n",
      "Epoch 84: val_loss did not improve from 2.02505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6311 - accuracy: 0.1795 - val_loss: 4.3547 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6278 - accuracy: 0.2051\n",
      "Epoch 85: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6278 - accuracy: 0.2051 - val_loss: 4.4035 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6251 - accuracy: 0.2564\n",
      "Epoch 86: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6251 - accuracy: 0.2564 - val_loss: 4.4490 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6229 - accuracy: 0.2821\n",
      "Epoch 87: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.6229 - accuracy: 0.2821 - val_loss: 4.4907 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6215 - accuracy: 0.3077\n",
      "Epoch 88: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6215 - accuracy: 0.3077 - val_loss: 4.5369 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6190 - accuracy: 0.3077\n",
      "Epoch 89: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6190 - accuracy: 0.3077 - val_loss: 4.5825 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6174 - accuracy: 0.2564\n",
      "Epoch 90: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6174 - accuracy: 0.2564 - val_loss: 4.6290 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6170 - accuracy: 0.2821\n",
      "Epoch 91: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.6170 - accuracy: 0.2821 - val_loss: 4.6721 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6175 - accuracy: 0.2821\n",
      "Epoch 92: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6175 - accuracy: 0.2821 - val_loss: 4.7050 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6174 - accuracy: 0.2821\n",
      "Epoch 93: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6174 - accuracy: 0.2821 - val_loss: 4.7273 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6160 - accuracy: 0.2821\n",
      "Epoch 94: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6160 - accuracy: 0.2821 - val_loss: 4.7420 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6139 - accuracy: 0.2821\n",
      "Epoch 95: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6139 - accuracy: 0.2821 - val_loss: 4.7525 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6120 - accuracy: 0.2821\n",
      "Epoch 96: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6120 - accuracy: 0.2821 - val_loss: 4.7627 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6103 - accuracy: 0.2821\n",
      "Epoch 97: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.6103 - accuracy: 0.2821 - val_loss: 4.7753 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6086 - accuracy: 0.2564\n",
      "Epoch 98: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6086 - accuracy: 0.2564 - val_loss: 4.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6068 - accuracy: 0.2821\n",
      "Epoch 99: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6068 - accuracy: 0.2821 - val_loss: 4.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6050 - accuracy: 0.2564\n",
      "Epoch 100: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6050 - accuracy: 0.2564 - val_loss: 4.8366 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6037 - accuracy: 0.2564\n",
      "Epoch 101: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6037 - accuracy: 0.2564 - val_loss: 4.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6031 - accuracy: 0.2821\n",
      "Epoch 102: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6031 - accuracy: 0.2821 - val_loss: 4.8860 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6027 - accuracy: 0.2564\n",
      "Epoch 103: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6027 - accuracy: 0.2564 - val_loss: 4.9058 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6021 - accuracy: 0.2051\n",
      "Epoch 104: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6021 - accuracy: 0.2051 - val_loss: 4.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6014 - accuracy: 0.2051\n",
      "Epoch 105: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6014 - accuracy: 0.2051 - val_loss: 4.9353 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6005 - accuracy: 0.2308\n",
      "Epoch 106: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6005 - accuracy: 0.2308 - val_loss: 4.9495 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5997 - accuracy: 0.2821\n",
      "Epoch 107: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5997 - accuracy: 0.2821 - val_loss: 4.9666 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5989 - accuracy: 0.2564\n",
      "Epoch 108: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5989 - accuracy: 0.2564 - val_loss: 4.9883 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5979 - accuracy: 0.2564\n",
      "Epoch 109: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5979 - accuracy: 0.2564 - val_loss: 5.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5967 - accuracy: 0.2821\n",
      "Epoch 110: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5967 - accuracy: 0.2821 - val_loss: 5.0448 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5956 - accuracy: 0.2564\n",
      "Epoch 111: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5956 - accuracy: 0.2564 - val_loss: 5.0765 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5946 - accuracy: 0.2821\n",
      "Epoch 112: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5946 - accuracy: 0.2821 - val_loss: 5.1072 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5938 - accuracy: 0.2821\n",
      "Epoch 113: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5938 - accuracy: 0.2821 - val_loss: 5.1345 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.5931 - accuracy: 0.2821\n",
      "Epoch 114: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5931 - accuracy: 0.2821 - val_loss: 5.1574 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5923 - accuracy: 0.2051\n",
      "Epoch 115: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5923 - accuracy: 0.2051 - val_loss: 5.1763 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5916 - accuracy: 0.2564\n",
      "Epoch 116: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5916 - accuracy: 0.2564 - val_loss: 5.1928 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5910 - accuracy: 0.2821\n",
      "Epoch 117: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5910 - accuracy: 0.2821 - val_loss: 5.2091 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5904 - accuracy: 0.2821\n",
      "Epoch 118: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5904 - accuracy: 0.2821 - val_loss: 5.2270 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5897 - accuracy: 0.2821\n",
      "Epoch 119: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5897 - accuracy: 0.2821 - val_loss: 5.2475 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5890 - accuracy: 0.2821\n",
      "Epoch 120: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5890 - accuracy: 0.2821 - val_loss: 5.2708 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5882 - accuracy: 0.2564\n",
      "Epoch 121: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5882 - accuracy: 0.2564 - val_loss: 5.2959 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5875 - accuracy: 0.2564\n",
      "Epoch 122: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5875 - accuracy: 0.2564 - val_loss: 5.3214 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5867 - accuracy: 0.2308\n",
      "Epoch 123: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5867 - accuracy: 0.2308 - val_loss: 5.3456 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5860 - accuracy: 0.2308\n",
      "Epoch 124: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5860 - accuracy: 0.2308 - val_loss: 5.3671 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5854 - accuracy: 0.2821\n",
      "Epoch 125: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5854 - accuracy: 0.2821 - val_loss: 5.3856 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5847 - accuracy: 0.2821\n",
      "Epoch 126: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5847 - accuracy: 0.2821 - val_loss: 5.4018 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5841 - accuracy: 0.2821\n",
      "Epoch 127: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5841 - accuracy: 0.2821 - val_loss: 5.4171 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5835 - accuracy: 0.2821\n",
      "Epoch 128: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5835 - accuracy: 0.2821 - val_loss: 5.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5830 - accuracy: 0.2308\n",
      "Epoch 129: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5830 - accuracy: 0.2308 - val_loss: 5.4516 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5824 - accuracy: 0.2308\n",
      "Epoch 130: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5824 - accuracy: 0.2308 - val_loss: 5.4726 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5818 - accuracy: 0.2308\n",
      "Epoch 131: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5818 - accuracy: 0.2308 - val_loss: 5.4960 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5812 - accuracy: 0.2564\n",
      "Epoch 132: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5812 - accuracy: 0.2564 - val_loss: 5.5207 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5806 - accuracy: 0.2821\n",
      "Epoch 133: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5806 - accuracy: 0.2821 - val_loss: 5.5451 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5800 - accuracy: 0.2821\n",
      "Epoch 134: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5800 - accuracy: 0.2821 - val_loss: 5.5681 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5794 - accuracy: 0.2821\n",
      "Epoch 135: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5794 - accuracy: 0.2821 - val_loss: 5.5888 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5789 - accuracy: 0.2564\n",
      "Epoch 136: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5789 - accuracy: 0.2564 - val_loss: 5.6074 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5783 - accuracy: 0.2308\n",
      "Epoch 137: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5783 - accuracy: 0.2308 - val_loss: 5.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5778 - accuracy: 0.2308\n",
      "Epoch 138: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5778 - accuracy: 0.2308 - val_loss: 5.6420 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5773 - accuracy: 0.2564\n",
      "Epoch 139: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5773 - accuracy: 0.2564 - val_loss: 5.6602 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5768 - accuracy: 0.2564\n",
      "Epoch 140: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5768 - accuracy: 0.2564 - val_loss: 5.6797 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5762 - accuracy: 0.2564\n",
      "Epoch 141: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5762 - accuracy: 0.2564 - val_loss: 5.6981 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5830 - accuracy: 0.2564\n",
      "Epoch 142: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5830 - accuracy: 0.2564 - val_loss: 5.7134 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5753 - accuracy: 0.2564\n",
      "Epoch 143: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5753 - accuracy: 0.2564 - val_loss: 5.7336 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5752 - accuracy: 0.2821\n",
      "Epoch 144: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5752 - accuracy: 0.2821 - val_loss: 5.7529 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5750 - accuracy: 0.2821\n",
      "Epoch 145: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5750 - accuracy: 0.2821 - val_loss: 5.7732 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5748 - accuracy: 0.2821\n",
      "Epoch 146: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5748 - accuracy: 0.2821 - val_loss: 5.7937 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5743 - accuracy: 0.2564\n",
      "Epoch 147: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5743 - accuracy: 0.2564 - val_loss: 5.8134 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5736 - accuracy: 0.2564\n",
      "Epoch 148: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5736 - accuracy: 0.2564 - val_loss: 5.8321 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5728 - accuracy: 0.2821\n",
      "Epoch 149: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5728 - accuracy: 0.2821 - val_loss: 5.8501 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5720 - accuracy: 0.2821\n",
      "Epoch 150: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5720 - accuracy: 0.2821 - val_loss: 5.8677 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5714 - accuracy: 0.2308\n",
      "Epoch 151: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5714 - accuracy: 0.2308 - val_loss: 5.8850 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5710 - accuracy: 0.2564\n",
      "Epoch 152: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5710 - accuracy: 0.2564 - val_loss: 5.9023 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5707 - accuracy: 0.2564\n",
      "Epoch 153: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5707 - accuracy: 0.2564 - val_loss: 5.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5704 - accuracy: 0.2564\n",
      "Epoch 154: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5704 - accuracy: 0.2564 - val_loss: 5.9362 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5700 - accuracy: 0.2821\n",
      "Epoch 155: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5700 - accuracy: 0.2821 - val_loss: 5.9529 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5696 - accuracy: 0.2821\n",
      "Epoch 156: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5696 - accuracy: 0.2821 - val_loss: 5.9696 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5690 - accuracy: 0.2821\n",
      "Epoch 157: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5690 - accuracy: 0.2821 - val_loss: 5.9865 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5685 - accuracy: 0.2564\n",
      "Epoch 158: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5685 - accuracy: 0.2564 - val_loss: 6.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5679 - accuracy: 0.2564\n",
      "Epoch 159: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5679 - accuracy: 0.2564 - val_loss: 6.0212 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5675 - accuracy: 0.2564\n",
      "Epoch 160: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5675 - accuracy: 0.2564 - val_loss: 6.0386 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5671 - accuracy: 0.2308\n",
      "Epoch 161: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5671 - accuracy: 0.2308 - val_loss: 6.0555 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5667 - accuracy: 0.2564\n",
      "Epoch 162: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5667 - accuracy: 0.2564 - val_loss: 6.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5664 - accuracy: 0.2821\n",
      "Epoch 163: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5664 - accuracy: 0.2821 - val_loss: 6.0872 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5660 - accuracy: 0.3077\n",
      "Epoch 164: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5660 - accuracy: 0.3077 - val_loss: 6.1022 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5656 - accuracy: 0.3077\n",
      "Epoch 165: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5656 - accuracy: 0.3077 - val_loss: 6.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5651 - accuracy: 0.2821\n",
      "Epoch 166: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5651 - accuracy: 0.2821 - val_loss: 6.1324 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5646 - accuracy: 0.2308\n",
      "Epoch 167: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5646 - accuracy: 0.2308 - val_loss: 6.1481 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5642 - accuracy: 0.2308\n",
      "Epoch 168: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5642 - accuracy: 0.2308 - val_loss: 6.1643 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5638 - accuracy: 0.2564\n",
      "Epoch 169: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5638 - accuracy: 0.2564 - val_loss: 6.1806 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5634 - accuracy: 0.2564\n",
      "Epoch 170: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5634 - accuracy: 0.2564 - val_loss: 6.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5631 - accuracy: 0.2564\n",
      "Epoch 171: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5631 - accuracy: 0.2564 - val_loss: 6.2123 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5627 - accuracy: 0.2564\n",
      "Epoch 172: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5627 - accuracy: 0.2564 - val_loss: 6.2273 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5623 - accuracy: 0.2564\n",
      "Epoch 173: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5623 - accuracy: 0.2564 - val_loss: 6.2417 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5619 - accuracy: 0.2564\n",
      "Epoch 174: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5619 - accuracy: 0.2564 - val_loss: 6.2560 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5615 - accuracy: 0.2821\n",
      "Epoch 175: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5615 - accuracy: 0.2821 - val_loss: 6.2703 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5611 - accuracy: 0.2821\n",
      "Epoch 176: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5611 - accuracy: 0.2821 - val_loss: 6.2851 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5607 - accuracy: 0.2564\n",
      "Epoch 177: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5607 - accuracy: 0.2564 - val_loss: 6.3001 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5604 - accuracy: 0.2308\n",
      "Epoch 178: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5604 - accuracy: 0.2308 - val_loss: 6.3155 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5600 - accuracy: 0.2308\n",
      "Epoch 179: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5600 - accuracy: 0.2308 - val_loss: 6.3307 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5597 - accuracy: 0.2308\n",
      "Epoch 180: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5597 - accuracy: 0.2308 - val_loss: 6.3457 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5593 - accuracy: 0.2308\n",
      "Epoch 181: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5593 - accuracy: 0.2308 - val_loss: 6.3601 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5589 - accuracy: 0.2308\n",
      "Epoch 182: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5589 - accuracy: 0.2308 - val_loss: 6.3740 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5586 - accuracy: 0.2308\n",
      "Epoch 183: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5586 - accuracy: 0.2308 - val_loss: 6.3875 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5582 - accuracy: 0.2308\n",
      "Epoch 184: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5582 - accuracy: 0.2308 - val_loss: 6.4009 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5578 - accuracy: 0.2564\n",
      "Epoch 185: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5578 - accuracy: 0.2564 - val_loss: 6.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5575 - accuracy: 0.2564\n",
      "Epoch 186: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5575 - accuracy: 0.2564 - val_loss: 6.4277 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5571 - accuracy: 0.2821\n",
      "Epoch 187: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5571 - accuracy: 0.2821 - val_loss: 6.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5568 - accuracy: 0.2821\n",
      "Epoch 188: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5568 - accuracy: 0.2821 - val_loss: 6.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5564 - accuracy: 0.2821\n",
      "Epoch 189: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5564 - accuracy: 0.2821 - val_loss: 6.4689 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5561 - accuracy: 0.2821\n",
      "Epoch 190: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5561 - accuracy: 0.2821 - val_loss: 6.4825 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5557 - accuracy: 0.2564\n",
      "Epoch 191: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5557 - accuracy: 0.2564 - val_loss: 6.4959 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5554 - accuracy: 0.2564\n",
      "Epoch 192: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5554 - accuracy: 0.2564 - val_loss: 6.5091 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5550 - accuracy: 0.2564\n",
      "Epoch 193: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5550 - accuracy: 0.2564 - val_loss: 6.5221 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5547 - accuracy: 0.2564\n",
      "Epoch 194: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5547 - accuracy: 0.2564 - val_loss: 6.5349 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5543 - accuracy: 0.2308\n",
      "Epoch 195: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5543 - accuracy: 0.2308 - val_loss: 6.5477 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5540 - accuracy: 0.2308\n",
      "Epoch 196: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5540 - accuracy: 0.2308 - val_loss: 6.5604 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5537 - accuracy: 0.2308\n",
      "Epoch 197: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5537 - accuracy: 0.2308 - val_loss: 6.5731 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5533 - accuracy: 0.2308\n",
      "Epoch 198: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5533 - accuracy: 0.2308 - val_loss: 6.5858 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5530 - accuracy: 0.2564\n",
      "Epoch 199: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5530 - accuracy: 0.2564 - val_loss: 6.5984 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5527 - accuracy: 0.2564\n",
      "Epoch 200: val_loss did not improve from 2.02505\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5527 - accuracy: 0.2564 - val_loss: 6.6108 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 16, 16, 16, 16, 16\n  y sizes: 49\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 49\u001b[0m\n\u001b[0;32m     45\u001b[0m     seq_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_lstm_model2.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history, seq_model\n\u001b[1;32m---> 49\u001b[0m _, sequence_model \u001b[38;5;241m=\u001b[39m run_experiment()\n",
      "Cell \u001b[1;32mIn[70], line 20\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m history \u001b[38;5;241m=\u001b[39m seq_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     10\u001b[0m     [train_data[\u001b[38;5;241m0\u001b[39m], train_data[\u001b[38;5;241m1\u001b[39m], train_data[\u001b[38;5;241m2\u001b[39m],train_data[\u001b[38;5;241m4\u001b[39m], train_data[\u001b[38;5;241m3\u001b[39m]],\n\u001b[0;32m     11\u001b[0m     train_labels,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint],\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m seq_model\u001b[38;5;241m.\u001b[39mload_weights(filepath)\n\u001b[1;32m---> 20\u001b[0m _, accuracy \u001b[38;5;241m=\u001b[39m seq_model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m     21\u001b[0m     [test_data[\u001b[38;5;241m0\u001b[39m], test_data[\u001b[38;5;241m1\u001b[39m], test_data[\u001b[38;5;241m2\u001b[39m], test_data[\u001b[38;5;241m3\u001b[39m], test_data[\u001b[38;5;241m4\u001b[39m]],\n\u001b[0;32m     22\u001b[0m     test_labels\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 손실 및 정확도 그래프 출력\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1953\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1954\u001b[0m         label,\n\u001b[0;32m   1955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1956\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1957\u001b[0m         ),\n\u001b[0;32m   1958\u001b[0m     )\n\u001b[0;32m   1959\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 16, 16, 16, 16, 16\n  y sizes: 49\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE= 128\n",
    "def run_experiment():\n",
    "    filepath = \"tmp/video_classifier_lstm.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1], train_data[2],train_data[3], train_data[4]],\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    \n",
    "    _, accuracy = seq_model.evaluate(\n",
    "        [test_data[0], test_data[1], test_data[2], test_data[3], test_data[4]],\n",
    "        test_labels\n",
    "    )\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    # 손실 및 정확도 그래프 출력\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    # 손실 그래프\n",
    "    ax1 = plt.subplot(1, 1, 1)\n",
    "    ax1.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', color='blue', linestyle='dashed')\n",
    "    ax1.set_title('Training and Validation Loss and Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax1.legend(loc='upper left')\n",
    "    # 정확도 그래프를 같은 그래프에 추가\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(history.history['accuracy'], label='Train Accuracy', color='green')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green', linestyle='dashed')\n",
    "    ax2.set_ylabel('Accuracy', color='green')\n",
    "    ax2.tick_params(axis='y', labelcolor='green')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    seq_model.save('test_lstm_model2.h5')\n",
    "    \n",
    "    return history, seq_model\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_video(frames, skeletons, hands, arm_angles):\n",
    "    num_frames = frames.shape[1]\n",
    "    video_length = min(MAX_SEQ_LENGTH, num_frames)\n",
    "\n",
    "    frame_mask = np.zeros((1, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros((1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float16\")\n",
    "    frame_skeletons = np.zeros((1, MAX_SEQ_LENGTH, SKELETON_FEATURES), dtype=\"float16\")\n",
    "    frame_hands = np.zeros((1, MAX_SEQ_LENGTH, HAND_FEATURES), dtype=\"float16\")\n",
    "    frame_images = np.zeros((1, MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=\"float16\")\n",
    "    frame_arm_angles = np.zeros((1, MAX_SEQ_LENGTH, 2), dtype=\"float16\")  # 2는 팔 각도 데이터 차원\n",
    "    \n",
    "    feature_extractor = Sequential([\n",
    "        ResNet50(include_top=False, weights='imagenet', pooling='avg'),  # 예시로 평균 풀링 사용\n",
    "        Dense(NUM_FEATURES, activation='relu')  # NUM_FEATURES에 맞는 덴스 레이어 추가\n",
    "    ])\n",
    "    \n",
    "    for j in range(video_length):\n",
    "        # 이미지 데이터 전처리 및 특징 추출\n",
    "        image_feature = preprocess_image(frames[j:j+1])\n",
    "        image_feature = np.expand_dims(image_feature, axis=0)\n",
    "        feature_result = feature_extractor.predict(image_feature)\n",
    "\n",
    "        # frame_images 대신 feature_result를 사용\n",
    "        frame_features[0, j] = feature_result\n",
    "\n",
    "        # Mediapipe 데이터 전처리\n",
    "        skeleton_feature = preprocess_skeleton_data(skeletons[j])\n",
    "        hand_feature = preprocess_hand_data(hands[j])        \n",
    "        arm_angle_feature = np.array(arm_angles[j])\n",
    "\n",
    "        frame_skeletons[0, j] = skeleton_feature\n",
    "        frame_hands[0, j] = hand_feature\n",
    "        frame_mask[0, j] = 1        \n",
    "        frame_arm_angles[0, j] = arm_angle_feature\n",
    "\n",
    "    return frame_features, frame_skeletons, frame_hands, frame_mask, frame_images, frame_arm_angles\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    frames, skeletons, hands, arm_angles = load_video(path)    \n",
    "    try:\n",
    "        num_frames = frames.shape[1]\n",
    "    except IndexError:\n",
    "        print(\"Error: Unable to determine the number of frames. Frames shape:\", frames.shape)\n",
    "        return None\n",
    "    \n",
    "    frame_features, frame_skeletons, frame_hands, frame_mask, frame_images, frame_arm_angles = prepare_single_video(frames, skeletons, hands, arm_angles)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_skeletons, frame_hands,frame_arm_angles, frame_mask])[0]\n",
    "    \n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"{class_vocab[i]} : {probabilities[i] * 100:5.2f}%\")\n",
    "    \n",
    "    return frame_images\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54b685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
